# Metrics Monitoring and Alerting System

- 이번 장에서는 확장성 있는 metric 모니터링 및 알림 시스템을 설계해볼 것이다.  
  잘 설계된 metric 모니터링 및 알림 시스템은 infrastructure가 고가용성과 안전성을 가지는 것을 보장하는 데 중요한 요소로 사용된다.

- 아래는 시장에 나와있는 유명한 metric 모니터링 및 알림 시스템들이다.

  - Datadog, Prometheus, Grafana
  - InfluxDB, New Relic, Nagios, Graphite

- 이번 장에서는 위와 비슷한 서비스를 만들고, 대형 회사들을 위한 시스템을 구축해보자.

## 문제 이해 및 설계 범위 확정

- Metric 모니터링 및 알림 시스템은 회사마다 매우 다르게 사용될 수 있으므로 설계 전에 정확히 요구사항들을 파악하는 것이 중요하다.  
  예를 들어 만약 intrastructure metric만 다뤄야 하는데 web server logging을 집중적으로 다루는 시스템을 설계하는 것은 옳지 않다.

- 이번에 설계할 시스템의 요구사항 및 추정치들은 아래와 같다.

  - 대형 규모의 infrastructure에 대한 모니터링을 제공한다.

    - DAU: 1억명
    - 1000개의 server pool이 있으며 각 pool에는 100개의 서버가 있고, 각 서버 당 100개의 metric을 기록한다.  
      따라서 1000만 개의 metric을 수집해야 한다.
    - 데이터 저장 기간: 1년
    - 데이터 저장 정책: 7일 동안 raw data form, 30일 동안 1 minute resolution, 1년 동안 1 hour resolution

  - 아래와 같이 다양한 metric 정보들이 모니터링되어야 한다.
    - CPU usage
    - Request count
    - Memoru usage
    - Message count in message queues

- 아래는 기능적 요구사항이 아닌 다른 요구사항들이다.

  - 확장성(scalability): 시스템은 늘어나는 metric과 알림 양을 적절히 처리하기 위해 확장 가능해야 한다.
  - Low latency: 시스템은 대시보드 및 알림을 위해 query의 latency가 낮게 유지해야 한다.
  - 안전성(reliability): 시스템은 중요한 알림이 누락되는 것을 막기 위해 굉장히 안전성이 높아야 한다.
  - 유연성(flexibility): 기술이 지속적으로 변하기 때문에 pipeline은 미래의 새로운 기술들에도 연동하기 쉽게 유연해야 한다.

- 아래는 이번 시스템에서 다루지 않을 범위 밖의 내용들이다.

  - Log monitoring: ElasticSearch, Logstash, Kibana(ELK) stack이 로그를 모으고 모니터링하기 위해 매우 유명한 기술들이다.
  - Distributed system tracing: Distributed tracing은 요청이 처리되기 위해 사용되는 분산 시스템의 모든 것을 추적하기 위한 솔루션이다.  
    Request가 하나의 서비스로부터 다른 서비스로 갈 때의 데이터들을 모은다.

---

## 개략적 설계안 제시 및 동의 구하기

- 이번에는 시스템을 만들기 위한 기본적인 내용(데이터 모델, 개략적 설계안)을 살펴보자.

### 기본 적인 내용들

- 아래는 metrics 모니터링 및 알림 시스템이 일반적으로 포함하는 5개의 컴포넌트들이다.

  - Data collection: 다양한 source들로부터 metric data를 모은다.
  - Data transmission: Source로부터 metrics 모니터링 시스템에게 데이터를 전송한다.
  - Data storage: 들어오는 데이터를 분류하고 저장한다.
  - Alerting: 들어오는 데이터를 분석하고 변칙적인 형태를 찾아내고 알림을 생성한다.  
    시스템은 다양한 communication channel들에게 알림을 보낼 수 있어야 한다.
  - Visualization: 데이터를 그래프, 차트 등으로 시각화한다. Enginner 입장에서는 데이터의 흐름, 문제, 패턴 등을 데이터가 시각화되었을 때  
    더욱 발견해내기 쉽다.

### Data Model

- Metric 데이터는 일반적으로 timestamp에 특정 값들을 연관시킨 time series로 저장된다.  
  Series 자체는 unique identifier로 구별될 수 있고, label들로 선택해낼 수도 있다.  
  2개의 예시들을 살펴보자.

#### Example 1

- 아래 그림에서 production server 인스턴스 i631의 20:00의 CPU load가 얼마일까?

![picture 83](/images/SDI2_MMAS_1.png)

- 위 표의 그래프에서 명시된 특정 부분은 아래의 table로 나타내어진다.

| type        | value               |
| ----------- | ------------------- |
| metric_name | cpu.load            |
| labels      | host:i631, env:prod |
| timestamp   | 1613707265          |
| value       | 0.29                |

- 이 예시에서 time series는 metric의 이름과 label들(`host:i631,env:prod`)로 표현되며 특정 시간의 값을 표현한다.

#### Example 2

- Us-west region에 있는 모든 웹 서버들의 최근 10분 동안 사용된 CPU load의 평균량은 얼마일까?

- 개념적으로 이를 위해 metric 이름이 `CPU.load`이고 region label에 `us-west`인 아래처럼 구성된 내용을 storage에서 찾아낼 것이다.

```
CPU.load host=webserver01,region=us-west 1613707265 50
CPU.load host=webserver01,region=us-west 1613707265 62
CPU.load host=webserver02,region=us-west 1613707265 43
CPU.load host=webserver02,region=us-west 1613707265 53

CPU.load host=webserver01,region=us-west 1613707265 76
CPU.load host=webserver01,region=us-west 1613707265 83
```

- 평균 CPU load는 위 내용의 각 줄마다의 마지막 값을 평균한 값이 될 것이다.  
  위처럼 줄 단위로 이뤄진 형식을 line protocol이라 한다.  
  Line protocol은 Prometheus, OpenTSDB 등 시장의 많은 모니터링 소프트웨어의 input format이다.

- 모든 time series 데이터는 아래의 내용을 포함한다.

| Name                                    | Type                                   |
| --------------------------------------- | -------------------------------------- |
| A metric name                           | String                                 |
| A set of tags/labels                    | List of `<key:value>` pairs            |
| An array of values and their timestamps | An array of `<value, timestamp>` pairs |

#### Data access pattern

- 아래 그림에서 y축의 각 label은 이름과 label로 구별될 수 있는 time series를 나타내며, x축은 시간을 나타낸다.

![picture 84](/images/SDI2_MMAS_2.png)

- 쓰기(write)를 위한 데이터가 많다. 위 그림에서 알 수 있듯이 어느 순간에 대해서도 저장될 수 있는 time series data가 매우 많을 수 있다.  
  이전에 요구사항을 파악할 때 대략 1000만 개의 운영 metric이 하루에 저장된다는 것을 파악했고 많은 metric은 짧은 주기로 자주 저장된다.  
  따라서 트래픽은 의심할 여지 없이 write-heavy 하다.

- 반면 read 연산량은 때에 따라 다르다. 시각화 및 알림 서비스 모두 데이터베이스에 query를 하며 graph와 알림의 access pattern에 따라 read volume은  
  클 수도 있고 작을 수도 있다.(spiky)

#### Data storage system

- 데이터 저장 시스템은 이 설계의 심장과도 같다. 직접 저장 시스템을 구축하거나 일반적인 용도를 위한 저장 시스템(ex. MySQL)은 이 시스템에 사용되기에  
  적합하지 않다.

- 이론적으로 general-purpose database도 time-series data를 지원하지만, 지금 설계하는 시스템의 규모에서 동작하도록 하려면 꽤나 전문가 수준의  
  tuning이 필요할 것이다. 특히 RDBMS는 time-series data에 대해 수행할 연산들에 대해 최적화되어 있지 않다. 예를 들어 자주 수정되는 특정 시간대의  
  평균값을 구하는 것은 읽기 어려운 SQL Query를 필요로 할 것이다. 그리고 데이터의 tagging/labeling을 지원하기 위해서는 각 tag에 대해 index를  
  만들어야 할 것이다. 그리고 general-purpose RDBMS는 무거운 write load가 지속적으로 발생할 때 퍼포먼스를 잘 내지 못한다.  
  지금 설계하는 시스템의 규모에서는 database tuning에 엄청난 노력이 필요할 것이고, 이를 하더라도 제대로 동작하지 못할 수 있다.

- NoSQL은 어떨까? 이론적으로 Cassandra, Bigtable 등 시장의 몇 가지 NoSQL database들은 time-series data를 효율적으로 다룰 수 있다.  
  하지만 효과적으로 time-series data를 저장하고 질의하기 위해서 확장 가능한 스키마를 설계하기 위해선 NoSQL의 내부 동작 방식 등 전문가 적인  
  지식을 필요로 할 것이다. 또한 대규모를 위한 time-series 전용 데이터베이스가 있다는 점을 감안하면 general-purpose NoSQL database를  
  사용하는 것은 그닥 매력적인 선택지가 아니다.

- Time-series data를 위해 최적화된 많은 storage system들이 존재한다. 이들은 time-series에 특화되어 최적화되어 있기 때문에  
  동일한 양의 데이터를 처리하기 위해서도 더 적은 개수의 서버를 필요로 하게 된다. 그리고 이들 중 많은 데이터베이스들이 time-series data의  
  분석을 위해 SQL보다 사용이 쉬운 custom query interface를 제공한다. 일부는 심지어 데이터의 취합(aggregation)과  
  데이터의 저장 주기(retention)를 관리하기 위한 기능도 지원한다. Time-series database의 몇 가지 예시들을 보자.

- OpenTSDB는 분산 time-series database이지만 Hadoop과 HBase에 기반하고 있기 때문에 사용하기 위해서는 Hadoop/HBase cluster를  
  함께 운영해야 하며, 이는 운영의 복잡도를 증가시킨다. Twitter는 MetricsDB를 사용하며 Amazon은 time-series database로  
  Timestream을 제공한다. 특정 설문 조사에 따르면 가장 유명한 time-series database는 InfluxDB와 Prometheus라고 한다.  
  이 둘은 매우 큰 규모의 time-series data를 저장하고 저장된 데이터에 대해 실시간 분석을 원활히 수행하는 것에 맞춰 설계되었다.  
  이 둘은 모두 in-memory cache와 on-disk storage 모두에 의존하며 내구성과 성능이 뛰어나다.  
  아래 표에 나타난 것처럼 8-cores, 32GB RAM으로 구성된 InfluxDB는 초당 250,000개의 write 연산을 처리할 수 있다.

  | vCPU or CPU | RAM     | IOPS     | Writes per second | Queries\* per second | Unique series |
  | ----------- | ------- | -------- | ----------------- | -------------------- | ------------- |
  | 2-4 cores   | 2-4 GB  | 500      | < 5,000           | < 5                  | < 100,000     |
  | 4-6 cores   | 8-32 GB | 500-1000 | < 250,000         | < 25                 | < 1,000,000   |
  | 8+ cores    | 32+ GB  | 1000+    | > 250,000         | > 25                 | > 1,000,000   |

- 강력한 time-series database가 제공하는 또다른 기능으로 많은 양의 time-series data들을 label(tag)를 기준으로 취합하고 분석하는 것이 있다.  
  예를 들어 InfluxDB는 label들에 대해 index를 생성해 label로 time-series data를 빠르게 찾아낼 수 있도록 한다. 그리고 데이터베이스에 부하를 주지  
  않으면서 label을 효율적으로 사용하기 위한 명확한 best-practice 가이드라인을 제시한다. 중요한 것은 각 label이 낮은 cardinality  
  (가능한 값들이 작은 집합이 되도록)를 갖게 하는 것이다. 이 기능은 시각화를 위해 굉장히 중요하며 이를 general-purpose database로 구현하기 위해서는  
  엄청난 노력이 들 것이다.

### 개략적 설계안

- 아래는 이 시스템의 개략적 설계안이다.

![picture 85](/images/SDI2_MMAS_3.png)

- 각 컴포넌트들을 간단히 보자.

  - Metrics source: 애플리케이션 서버, SQL Database, message queue 등 metric을 수집해야 하는 컴포넌트
  - Metrics collector: Metric data를 모아 time-series database에 저장한다.
  - Time-series DB: Metric data를 time-series로 저장한다. 일반적으로 대량의 time-series data에 대해 분석, 요약 등을 수행할 수 있도록  
    custom query interface를 제공한다.
  - Query service: Query service는 time-series database에게 질의하고 데이터를 가져오기 쉽게 해준다.  
    이 서비스는 좋은 time-series database를 사용한다면 매우 가벼운 wrapper에 불과할 것이다. 그리고 이 서비스의 인터페이스는 time-series  
    database 자신의 query interface와 100% 호환되어야 한다.
  - Alerting System: 다양한 목적지로 알림을 전송한다.
  - Visualization system: Metric 정보를 다양한 형태의 그래프, 차트 등으로 시각화해 보여준다.

---

## 상세 설계

### Metrics collection

#### Pull vs Push models

#### Pull model

#### Push model

#### Pull or push?

### Scaling the metrics transmission pipleine

#### Scale through Kafka

#### Alternative to Kafka

#### Where aggregations can happen

### Query service

#### Cache layer

#### The case against query service

#### Time-series database query language

### Storage layer

#### Choose a time-series database carefully

#### Space optimization

#### Data encoding and compression

#### Downsampling

#### Cold storage

### Aletering system

#### Alerting system - build vs buy

### Visualization system

---
