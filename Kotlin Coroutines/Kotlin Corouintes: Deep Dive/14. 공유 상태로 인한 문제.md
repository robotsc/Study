# 공유 상태로 인한 문제

- 아래의 `UserDownloader` 를 살펴보자. 아래처럼 구현하면 어떤 문제가 있을까?

```kt
class UserDownloader(
	private val api: NetworkService
) {
	private val users = mutableListOf<User>()

	fun downloaded(): List<User> = users.toList()

	suspend fun fetchUser(id: Int) {
		val newUser = api.fetchUser(id)
		users.add(newUser)
	}
}
```

- 위 구현 방식은 동시 사용에 대한 대비가 되어 있지 않다.  
  `fetchUser()` 의 호출은 users를 변경한다.  
  이 경우 같은 시간에 해당 함수가 한 개의 스레드에서 시작할 경우에만 정상적으로 작동한다.  
  같은 시간에 두 개 이상의 스레드에서 함수가 호출될 수 있으므로 users는 공유 상태에 해당하며, 보호될 필요가 있다.  
  동시에 리스트를 변경하면 충돌이 일어날 수 있기 때문이다.

- 아래 예시는 충돌이 일어나는 경우를 나타낸다.

```kt
class FakeNetworkService : NetworkService {
	override suspend fun fetchUser(id: Int): User {
		delay(2)
		return User("User$id")
	}
}

suspend fun main() {
	val downloader = UserDownloader(FakeNetworkService())
	coroutineScope {
		repeat(1_000_000) {
			launch {
				downloader.fetchUser(it)
			}
		}
	}
	println(downloader.downloaded().size) // ~998242
}
```

- 같은 객체와 상호작용하는 스레드가 많기에 위 코드는 1,000,000 보다 작은 숫자를 출력하거나 예외를 던지게 된다.

- 위와 같은 문제는 공유 상태를 변경할 때 쉽게 만날 수 있다.  
  조금 더 간단히 생각해, 하나의 정수를 1씩 증가시키는 스레드가 여러 개 있다고 해보자.  
  아래에서는 `Dispatchers.Default` 를 사용하는 1,000개의 코루틴에서 1,000번의 연산을 호출하는  
  `massiveRun()` 을 사용한다. 모든 연산이 끝난 뒤 숫자는 `1,000,000(1000 * 1000)` 이 되어야 한다.  
  하지만 동기화되지 않으면 충돌이 발생하므로 실제 결과는 이보다 더 작다.

```kt
var counter = 0

fun main() = runBlocking {
	massiveRun { counter++ }
	println(counter) // ~567231
}

suspend fun massiveRun(action: suspend () -> Unit) =
	withContext(Dispatchers.Default) {
		repeat(1000) {
			launch {
				repeat(1000) { action() }
			}
		}
	}
```

- 결과가 1,000,000이 아니라는 것을 이해하기 위해 두 개의 스레드가 똑같은 시간에 같은 수를 1씩 증가시킨다고 가정해보자.  
  시작값은 0이다. 첫 번째 스레드가 현재 값인 0을 받고 난 뒤, 프로세서가 두 번째 스레드로 옮기기로 결정한다.  
  두 번째 스레드 또한 0을 받고 1로 증가시킨 뒤 변수에 저장한다.  
  첫 번째 스레드로 다시 옮긴다면 이전에 멈췄을 때 사용한 0을 1로 증가시키고 저장한다.  
  그 결과 변수는 2가 되어야 하지만, 실제로는 1이 되어버린다. 이 때문에 연산 일부가 반영되지 않는 결과가 일어난다.

---

## 동기화 blocking

- 위와 같은 문제는 Java에서 사용되는 전통적인 도구인 `synchronized` block이나 동기화된 collection을 사용해 해결할 수 있다.

```kt
var counter = 0

fun main() = runBlocking {
	val lock = Any()
	massiveRun {
		synchronized(lock) {
			counter++
		}
	}
	println("Counter = $counter") // Counter = 1000000
}
```

- 위 방법은 잘 작동하지만, 몇 가지 문제점이 있다.  
  가장 큰 문제점은 `synchronized` block 내부에서 중단 함수를 사용할 수 없다는 것이다.  
  두 번째는 `synchronized` block에서 코루틴이 자신의 차례를 기다릴 때 스레드를 blocking한다는 것이다.  
  Dispatcher의 원리를 생각해보면, 코루틴이 스레드를 blocking하는 것은 지양해야 한다.  
  Main thread가 blocking되면 어떻게 될까? 제한된 수의 스레드만 가지다면 어떻게 될까? 왜 스레드 같은 자원을 낭비해야 할까?

- 이런 방법 대신 코루틴에 특화된 방법을 사용해야 한다. Blocking 없이 중단하거나 충돌을 회피하는 방법을 사용해야 한다.

---

## 원자성

- Java에는 간단한 경우에 사용할 수 있는 다른 방법이 있다.  
  Java는 다양한 원자값을 가지는데, 원자값을 활용한 연산은 빠르며 thread safety를 보장한다.  
  이러한 연산을 thread-safe 연산이라 한다.  
  원자성 연산은 lock 없이 low-level로 구현되어 있기에 효율적이고 사용하기가 쉽다.  
  사용할 수 있는 원자값의 종류는 다양한데, 여기서는 `AtomicInteger` 를 사용해보자.

```kt
private var counter = AtomicInteger()

fun main() = runBlocking {
	massiveRun { counter.incrementAndGet() }
	println(counter.get()) // 1000000
}
```

- 원자값은 의도한 대로 완벽하게 동작하지만, 사용성이 제한되기에 조심해서 다뤄야한다.  
  하나의 연산에서 원가성을 가지고 있다고 해서 전체 연산에서 원자성이 보장되는 것은 아니기 때문이다.

```kt
private var counter = AtomicInteger()

fun main() = runBlocking {
	massiveRun { counter.set(counter.get() + 1) }
	println(counter.get()) // ~430467
}
```

- `UserDownloader` 를 안전하게 사용하기 위해 읽기만 가능한 사용자들의 리스트를 `AtomicReference` 로 wrapping할 수도 있다.  
  충돌 없이 값을 갱신하기 위해서는 `getAndUpdate()` 라는 원자성을 보장해주는 함수를 이용해야 한다.

```kt
class UserDownloader(
	private val api: NetworkService
) {
	private val users = AtomicReference(listOf<User>())

	fun downloaded(): List<User> = users.get()

	suspend fun fetchUser(id: Int) {
		val newUser = api.fetchUser(id)
		users.getAndUpdate { it + newUser }
	}
}
```

- 원자성은 하나의 primitive 변수 또는 하나의 reference의 안전을 보장하기 위해 사용되지만, 좀 더 복잡한 경우에는 다른 방법을 사용해야 한다.

---

## Single thread로 제한된 dispatcher

- 이전에 병렬성을 하나의 스레드로 제한하는 dispatcher를 살펴보았다.  
  이런 single thread dispatcher를 사용하는 것이 공유 상태와 관련된 대부분의 문제를 해결하는 가장 쉬운 방법이다.

```kt
val dispatcher = Dispatchers.IO.limitedParallelism(1)

var counter = 0

fun main() = runBlocking {
	massiveRun {
		withContext(dispatcher) { counter++ }
	}
	println(counter) // 1000000
}
```

- 두 가지 방법으로 dispatcher를 사용할 수 있다.  
  첫 번째 방법은 coarse-grained thread confinement으로 알려져 있다.  
  이 방법은 dispatcher를 single thread로 제한한 `withContext()` 로 전체 함수를 wrapping하는 방식이다.  
  사용하기 쉽고 충돌을 방지할 수 있지만, 함수 전체에서 multi-threading의 이점을 누리지 못하는 문제가 있다.

- 아래 예시를 보자. `api.fetchUser(id)`는 여러 개의 스레드에서 병렬로 시작할 수 있지만,  
  함수 본체는 single thread로 제한된 dispatcher에서 실행된다.  
  그 결과 blocking되는 함수 또는 CPU-intensive한 함수를 호출하면 함수 실행이 느려진다.

```kt
class UserDownloader(private val api: NetworkService) {
	private val users = mutableListOf<User>()
	private val dispatcher = Dispatchers.IO.limitedParallelism(1)

	suspend fun downloaded(): List<User> =
		withContext(dispatcher) { users.toList() }

	suspend fun fetchUser(id: Int) = withContext(dispatcher) {
		val newUser = api.fetchUser(id)
		users += newUser
	}
}
```

- 두 번째 방법으로는 fine-grained thread confinement가 있다.  
  이 방법은 상태를 변경하는 구문들만 wrapping한다. 이 예시 코드에서는 users를 사용하는 모든 줄에 해당한다.  
  Fine-grained thread confinement는 좀 더 번거롭지만, critical section이 아닌 부분이 blocking되거나  
  CPU-intensive한 경우에 더 나은 성능을 제공한다. 일반적인 중단 함수에 적용하는 경우에는 성능에 큰 차이가 없다.

```kt
class UserDownloader(private val api: NetworkService) {
	private val users = mutableListOf<User>()
	private val dispatcher = Dispatchers.IO.limitedParallelism(1)

	suspend fun downloaded(): List<User> =
		withContext(dispatcher) { users.toList() }

	suspend fun fetchUser(id: Int) {
		val newUser = api.fetchUser(id)
		withContext(dispatcher) {
			users += newUser
		}
	}
}
```

- 대부분의 경우에는 표준 dispatcher가 같은 thread pool을 사용하기 때문에 single threaded dispatcher를 사용하는 것은 쉬울 뿐만 아니라 효율적이다.

---

## Mutex

- 마지막으로 인기있는 방식은 `Mutex` 를 사용하는 것이다.  
  `Mutex`는 단 하나의 열쇠가 있는 방이라고 생각하면 된다.  
  `Mutex`의 가장 중요한 기능은 `lock()` 이다.  
  첫 번째 코루틴이 `lock()` 을 호출하면, 열쇠를 가지고 중단 없이 작업을 수행한다.  
  또 다른 코루틴이 `lock()` 을 호출하면, 첫 번째 코루틴이 `unlock()` 을 호출할 때까지 중단된다.  
  또 다른 코루틴이 `lock()` 을 호출함면, 마찬가지로 작업을 중단한 뒤에 두 번째 코루틴 다음 순서로 queue에 들어가게 된다.  
  첫 번째 코루틴이 `unlock()` 을 호출해 열쇠를 반납하면 두 번째 코루틴이 재개한 뒤 `lock()` 을 통과하게 된다.  
  따라서 단 하나의 코루틴만이 `lock()` 와 `unlock()` 사이에 있을 수 있다.

```kt
suspend fun main() = coroutineScope {
	repeat(3) {
		launch { delayAndPrint() }
		}
	}

val mutex = Mutex()

suspend fun delayAndPrint() {
	mutex.lock()
	delay(1000)
	println("Done")
	mutex.unlock()
}

// (1초 후)
// Done
// (1초 후)
// Done
// (1초 후)
// Done
```

- `lock()`과 `unlock()` 을 직접 사용하는 것은 위험한데, 두 함수 사이에서 예외가 발생하거나  
  return이 빠르게 되는 경우 열쇠를 돌려받지 못해 다른 코루틴이 `lock()` 을 통과하지 못하게 될 수 있다.  
  이런 문제를 deadlock 이라고 한다.  
  대신 `lock()` 으로 시작해 finally block에서 `unlock()` 을 호출하는 `withLock()` 함수를 사용해  
  block 내에서 어떤 예외가 발생하더라도 항상 열쇠를 반납하게 할 수 있다.

- 실제 사용법은 synchronized block과 비슷하다.

```kt
val mutex = Mutex()

var counter = 0

fun main() = runBlocking {
	massiveRun {
		mutex.withLock { counter++ }
	}
	println(counter) // 1000000
}
```

- synchronized block과 달리 mutex가 가지는 중요한 이점은 스레드를 blocking하는 대신 코루틴을 중단시킨다는 것이다.  
  좀 더 안전하고 가벼운 방식이라는 것이다.

- 병렬 실행이 single threaded dispatcher를 사용하는 것과 비교하면 mutex가 가벼우며, 좀 더 나은 성능을 가질 수 있다.  
  하지만 적절히 사용하는 것 또한 어렵다. Mutex를 사용할 때마다 맞닥뜨리는 위험한 경우는 코루틴이 lock을 두 번 통과할 수 없다는 것이다.

- 아래 코드를 실행하면 프로그램은 deadlock에 빠지게 되며, 영원히 blocking 상태로 남아있게 된다.

```kt
suspend fun main() {
	val mutex = Mutex()
	println("Started")
	mutex.withLock {
		mutex.withLock {
			println("Will never be printed")
		}
	}
}

// Started
// (영원히 실행)
```

- Mutex의 두 번째 문제점은 코루틴이 중단되었을 때 lock을 풀 수 없다는 것이다. 아래 코드는 `delay()` 중에 mutex가 잠겨있어 5초가 걸린다.

```kt
class MessagesRepository {
	private val messages = mutableListOf<String>()
	private val mutex = Mutex()

	suspend fun add(message: String) = mutex.withLock {
		delay(1000)
		messages.add(message)
	}
}

suspend fun main() {
	val repo = MessagesRepository()

	val timeMillis = measureTimeMillis {
		coroutineScope {
			repeat(5) {
				launch {
					repo.add("Message$it")
				}
			}
		}
	}

	println(timeMillis) // ~5120
}
```

- 따라서 전체 함수를 mutex로 wrapping하는 것은 지양해야 한다. (coarse-grained 방식)
- Mutex를 사용하기로 했다면 lock을 두 번 걸지 않고, 중단 함수를 호출하지 않도록 신경써야 한다.

```kt
class MongoUserRepository(/* .. */) : UserRepository {
	private val mutex = Mutex()

	override suspend fun updateUser(
		userId: String,
		userUpdate: UserUpdate
	): Unit = mutex.withLock {
		val currentUser = getUser(userId) // DEADLOCK
		deleteUser(userId) // DEADLOCK
		addUser(currentUser.updated(userUpdate)) // DEADLOCK
	}

	override suspend fun getUser(userId: String): User = mutex.withLock {
		/* .. */
	}

	override suspend fun deleteUser(user: User): Unit = mutex.withLock {
		/* .. */
	}

	override suspend fun addUser(user: User): User = mutex.withLock {
		/* .. */
	}
}
```

---

## Semaphore

- `Mutex` 에 대해 알았다면 이제는 비슷한 방식으로 작동하지만, 둘 이상이 접근할 수 있고, 사용법이 다른 semaphore도 알아야 한다.  
  `Mutex`는 하나의 접근만 하용하므로 `lock()`, `unlock()`, `withLock()` 함수를 가진다.  
  `Semaphore` 는 여러 개의 접근을 허용하므로 `acquire()`, `release()`, `withPermit()` 함수를 가진다.

```kt
suspend fun main() = coroutineScope {
	val semaphore = Semaphore(2)

	repeat(5) {
		launch {
			semaphore.withPermit {
				delay(1000)
				println(it)
			}
		}
	}
}

// 01
// (1초 후)
// 23
// (1초 후)
// 4
```

- Semaphore는 공유 상태로 인해 생기는 문제를 해결할 수는 없지만, 동시 요청을 처리하는 수를 제한할 때 사용할 수 있어 rate limiter를 구현할 때 도움이 된다.

---
