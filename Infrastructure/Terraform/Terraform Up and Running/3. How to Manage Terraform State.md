# How to Manage Terraform State

- `terraform apply` 또는 `terraform plan`을 수행할 때마다 Terraform은 자동으로 이전에 자신이 생성한 리소스를  
  확인하고, 해당 내용에 바탕으로 갱신 사항들을 만들어 보여줬다. 어떻게 이를 알 수 있을까? AWS에 직접 콘솔로, Terraform으로,  
  혹은 CLI 등의 다양한 방법으로 생성한 리소스들이 있을 것인데, Terraform은 어떻게 자신이 책임져야 하는 리소스를 구분지을 수 있을까?

- 이번 장에서는 Terraform이 인프라의 상태를 어떻게 관리하는지 파악해볼 것이다.

## What is Terraform state?

- Terraform을 실행할 때마다 Terraform은 생성된 인프라에 대한 정보를 _Terraform state file_ 에 저장한다.  
  만약 Terraform을 `/foo/bar` 폴더에서 실행한다면, Terraform은 `/foo/bar/terraform.tfstate` 파일을 생성한다.  
  이 파일은 JSON 형식으로, configuration file 내의 Terraform 리소스들과 실제로 배포된 리소스의 매핑 관계를 나타낸다.

- `terraform plan` 명령의 결과는 컴퓨터에 있는 state와 실제 클라우드 리소스의 state 사이의 diff 이다.

> State file은 Terraform 내부에서 사용되기 위한 private API 형식으로, 절대로 직접 해당 파일의 내용을 수정해서는 안된다.  
> 물론 이 상태 파일을 수정해야 할 경우도 있을 것이다. 주로 `terraform import` 또는 `terraform state` 명령을 사용할 때이다.

- Terraform을 개인적인 프로젝트에서 사용할 때 모든 상태를 로컬 컴퓨터에 하나의 `terraform.tfstate` 파일에 저장해도 무방하다.  
  하지만 만약 실제 프로덕트에 대해 Terraform을 팀 단위로 활용할 때 이렇게 진행하면 아래의 문제점들을 만날 수 있다.

  - Shared storage for state files: 팀원 각각이 동일한 Terraform state file을 사용할 수 있어야 한다.  
    즉, 로컬 컴퓨터에 저장해서는 안되고 공유 스토리지에 저장해야 한다.

  - Locking state files: 데이터가 공유되는 순간, locking 문제에 직면하게 된다. Locking이 없다면 팀원 두 명이  
    동일한 시점에 Terraform을 실행할 경우 Terraform이 동시적으로 리소스를 갱신하려는 등의 상황이 발생하면서  
    race condition이 발생할 수 있다.

  - Isolating state files: 인프라에 변경 사항을 적용할 때, 좋은 방법은 환경을 격리하는 것이다.  
    예를 들어, 개발 환경에 변경 사항을 만들 때 상용 환경에는 전혀 영향이 없을 것임을 보장해야 한다.

---

## Shared Storage for State Files

- 여러 명의 사람들이 동일한 코드를 사용할 때 가장 많이 사용되는 방법은 Git 등의 VCS를 사용하는 것이다.  
  하지만 Terraform state 파일을 VCS에 저장해 공유하는 것은 다음의 문제들을 야기할 수 있다.

  - Manual error: Terraform을 실행하기 전 최신 상태를 pull하는 것을 까먹는 것은 너무나 흔한 일이다.  
    또한 변경 후 push하는 것을 까먹을 수도 있다. 즉, 이렇게 human error가 발생할 여지가 너무나 많다.

  - Locking: 대부분의 VCS는 두 명 이상의 사람들이 동시에 `terraform apply`를 실행하는 것을 방지하기 위한 locking  
    기능을 제공하지 않는다.

  - Secrets: Terraform state 파일의 모든 데이터는 plain text로 저장된다. 이는 일부 Terraform 리소스들이 민감 정보를  
    담고 있을 수도 있기에 보안 문제가 된다.

- 따라서 state file을 공유하기 위해서는 VCS보다 Terraform이 built-in으로 제공하는 remote backend를 사용하는 것이 좋다.  
  Terraform _backend_ 는 Terraform이 상태를 어떻게 불러오고, 저장하는지를 정의한다. Default backend는 지금까지 우리가  
  사용해왔던 _local backend_ 로, 모든 상태 파일을 로컬 디스크에 저장한다. _Remote backend_ 는 state file을 Amazon S3,  
  GCS, Azure Storage, Terraform Cloud 등 state file을 원격의 공유 저장소에 저장한다.

- Remote backend를 활용하는 것은 위에서 봤던 local backend의 세 가지 문제점들을 아래처럼 해결한다.

  - Manual error: Remote backend를 설정하면 Terraform은 자동으로 `plan` 또는 `apply`를 수행할 때 remote storage로부터  
    가장 최신 상태 파일을 불러오고, `apply` 후에는 자동으로 remote storage에 업데이트한다.

  - Locking: 대부분의 remote backend는 locking을 기본 기능으로 제공한다. `terraform apply`를 수행하면 Terraform이  
    자동으로 lock을 획득하게 되고, 만약 동시에 다른 누군가가 `apply`를 이미 하고 있다면 대기하게 된다.  
    `terraform apply`에 `-lock-timeout=<TIME>` 파라미터를 사용하면 Terraform이 lock을 획득할 때까지 기다리는 시간을  
    지정할 수 있다.

  - Secrets: 대부분의 remote backend는 encryption-in-transit과 encryption-at-rest를 기본적으로 지원한다.  
    여기에 더해 대부분의 remote storage는 접근 권한을 지정할 수 있기 때문에 state file을 안전하게 보호할 수 있다.

- Amazon S3를 remote backend로 활용해보자.  
   첫 번째로는 S3 bucket을 생성해야 한다. 아래처럼 bucket, bucket versioning 설정, server-side encryption, 그리고  
   public access block 설정을 모두 지정해주자.

```tf
provider "aws" {
  region = "us-east-2"
}

resource "aws_s3_bucket" "terraform_state" {
  bucket = "terraform-up-and-running-state-roy-ra"
  lifecycle {
    prevent_destroy = true
  }
}

resource "aws_s3_bucket_versioning" "enabled" {
  bucket = aws_s3_bucket.terraform_state.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "default" {
  bucket = aws_s3_bucket.terraform_state.id
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "aws_s3_bucket_public_access_block" "public_access" {
  bucket                  = aws_s3_bucket.terraform_state.id
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}
```

- 다음으로는 locking을 위해 사용할 DynamoDB table을 생성해보자.  
  DynamoDB를 Terraform을 위해 활용할 때는 primary key가 무조건 `LockID`여야 한다.

```tf
resource "aws_dynamodb_table" "terraform_locks" {
  name         = "terraform-up-and-running-locks-roy-ra"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"
  attribute {
    name = "LockID"
    type = "S"
  }
}
```

- 이 상태에서 `terraform init`으로 provider code를 받고, `terraform apply`를 수행해 S3 Bucket과 DynamoDB table이  
  생성되어도, Terraform state 파일은 여전히 local에 저장될 것이다. 즉, S3 bucket에 state 파일을 저장하게끔 하기 위해서는  
  별도의 설정이 필요하다. 바로 `backend` configuration이다. 이 설정은 Terraform 자체를 위한 설정이기 때문에 `terraform`  
  block에 아래의 문법으로 지정한다.

  ```tf
  terraform {
  	backend "<BACKEND_NAME>" {
  		[CONFIG...]
  	}
  }
  ```

  - `BECKEND_NAME`: 사용할 backend
  - `CONFIG`: backend에 따라 다르지만 대부분은 `bucket`, `key`, `region`, `dynamodb_table` 등이 있다.

- S3, DynamoDB table을 backend로 활용하기 위한 설정은 아래와 같다.

```tf
terraform {
  backend "s3" {
    bucket         = "terraform-up-and-running-state-roy-ra"
    key            = "global/s3/terraform.tfstate"
    region         = "us-east-2"
    dynamodb_table = "terraform-up-and-running-locks-roy-ra"
    encrypt        = true
  }
}
```

- 이제 `terraform init`을 수행하면 backend 관련 설정이 진행되고 있다는 문구가 나오고, 바로 S3에 state 파일이 저장되는 것을 확인할 수 있다.

- 이 상태에서 `terraform apply`, `terraform plan` 등을 실행하면 Terraform은 자동으로 S3에서 최신 상태를 가져오고, 변경 사항을  
  반영한 후 S3에 업데이트한다. 이 과정을 보고 싶다면 아래의 output variable들을 작성해보자.

```tf
output "s3_bucket_arn" {
  value       = aws_s3_bucket.terraform_state.arn
  description = "The ARN of the S3 bucket used to store Terraform state"
}

output "dynamodb_table_name" {
  value       = aws_dynamodb_table.terraform_locks.name
  description = "The name of the DynamoDB table used to store Terraform state locks"
}
```

- 이제 `terraform apply`를 수행하면 아래와 같이 출력된다.

  ```sh
  > terraform apply
  Acquiring state lock. This may take a few moments...
  ...
  Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

  Releasing state lock. This may take a few moments...

  Outputs:

  dynamodb_table_name = "terraform-up-and-running-locks-roy-ra"
  s3_bucket_arn = "arn:aws:s3:::terraform-up-and-running-state-roy-ra"
  ```

- 위 결과를 통해 Terraform이 apply 전에 lock을 획득하고, apply 후에 해제하는 것을 확인할 수 있다.

- S3 Bucket의 bucket versioning이 활성화되어 있기 때문에 state 파일이 바뀔 때마다 새로운 버전이 적용되고, 이는 이후에  
  디버깅, rollback 등을 쉽게 수행하도록 도와준다.

---

## Limitations with Terraform's Backends

- Terraform backend는 알아둬야 할 몇 가지 한계점들이 존재한다.  
  첫 번째 한계점은 Terraform을 사용해 Terraform state 파일을 관리할 bucket을 만들었다는 점에 있다.  
  우리는 이를 위해 아래 두 단계를 수행했다.

  - (1) S3 bucket, DynamoDB table 생성을 위한 Terraform code 작성 및 local backend로 배포
  - (2) Terraform code를 수정해 backend configuration 도입 후 `terraform init` 수행

- 만약 S3 bucket 혹은 DynamoDB table을 삭제하고 싶다면, 위 과정을 반대로 수행해야 한다.

  - (1) Terraform code의 backend 설정 제거 후 `terraform init`을 수행해 Terraform state를 local disk에 저장
  - (2) `terraform destroy`를 수행해 S3 bucket, DynamoDB table 삭제

- 이 두 단계 과정은 어색할 수 있지만, Terraform code의 상태를 관리하기 위해 S3 bucket과 DynamoDB table을 공유할 수 있기에  
  단순하다고 할 수도 있다.

- 두 번째 한계점은 `backend` block에서 변수 혹은 참조를 사용할 수 없다는 것이다. 즉, 아래와 같은 코드는 불가능하다.

```tf
terraform {
  backend "s3" {
    bucket         = var.bucket
    key            = var.key
    region         = var.region
    dynamodb_table = var.dynamodb_table
    encrypt        = true
  }
}
```

- 이는 곧 이후에 배울 Terraform module 각각에 대해 S3 bucket 이름, DynamoDB table 이름 등을 일일히 복붙해야 한다는  
  것을 의미한다. 거기에 더해 key는 module마다 달라야하기 때문에 key는 _주의해서_ 복붙해야 한다는 점도 있다.

- 이러한 복붙 단점을 해결하기 위한 한 가지 방법으로 _partial configuration_ 을 활용할 수 있는데, 이는 `backend` 설정의  
  일부 파라미터들을 CLI의 `-backend-config` 옵션으로 잔달하는 방법을 의미한다. 예를 들어 반복되는 `backend` 값들을  
  `backend.hcl`이라는 별도의 파일로 분리할 수 있다.

```hcl
bucket         = "terraform-up-and-running-state-roy-ra"
region         = "us-east-2"
dynamodb_table = "terraform-up-and-running-locks-roy-ra"
encrypt        = true
```

- 그리고 Terraform code에는 key만을 남겨둔다.

```tf
terraform {
  backend "s3" {
    key = "global/s3/terraform.tfstate"
  }
}
```

- 이제 `terraform init -backend-config=backend.hcl`을 수행하면 Terraform이 partial configuration 값들을  
  Terraform code에 병합해 필요한 모든 값들이 구성되어 있는 configuration을 구성해 적용한다.

---

## State File Isolation

- Remote backend와 locking을 구성했으므로 이제 여러 명의 사람들이 동일한 Terraform code를 공유해 사용하는 것은 문제가 없다.  
  하지만 아직 한 가지 문제가 남아있는데, 바로 _격리_ 이다. 처음 Terraform을 사용할 때는 모든 인프라를 하나의 Terraform file에  
  저장하고 싶을 수 있지만, 이렇게 하면 모든 Terraform state들이 하나의 파일에 저장되기 때문에 작은 실수로 인해 큰 악영향이 발생할 수 있다.

- 예를 들어 개발 환경에 애플리케이션의 새로운 버전을 배포하고 싶을 때, 상용 환경의 애플리케이션을 건드리게될 수 있다.

- 애초에 분리된 환경을 구성하는 이유가 서로를 격리시키기 위함인데, 모든 리소스를 하나의 Terraform code로 관리하는 것은 이를  
  위배하게 된다. 아래 그림처럼 Terraform configuration들을 분리해야 한다.

  ![picture 1](/images/TFRU_12.png)

- 이렇게 환경을 분리하는 방법은 아래의 두 가지 방식이 있다.

### Isolation via Workspaces

- _Terraform workspaces_ 는 Terraform state를 여러 개의 분리된 workspace로 나누어 저장하는 기능이다.  
  Terraform은 기본적으로 "default"라는 하나의 workspace를 사용하며, workspace를 명시적으로 지정하지 않으면  
  계속해서 default workspace를 사용하게 된다. 새로운 workspace를 생성하거나 다른 workspace를 사용하기 위해서는  
  `terraform workspace` 명령을 사용하면 된다.

- Workspace를 간단히 사용해보자.  
  아래 코드처럼 EC2 instance 하나와 remote backend를 사용하기 위한 코드를 별도의 폴더에 생성하고  
  `terraform init`을 수행하고, `terraform apply`를 수행해보자.

```tf
provider "aws" {
  region = "us-east-2"
}

resource "aws_instance" "example" {
  ami           = "ami-0fb653ca2d3203ac1"
  instance_type = "t2.micro"
}

terraform {
  backend "s3" {
    bucket         = "terraform-up-and-running-state-roy-ra"
    key            = "workspaces-example/terraform.tfstate"
    region         = "us-east-2"
    dynamodb_table = "terraform-up-and-running-locks-roy-ra"
    encrypt        = true
  }
}
```

- 하나의 EC2 instance가 배포된 후 현재 작업중인 workspace를 보여주는 `terraform workspace show`를 수행하면, 아래처럼 default가 나온다.

  ```sh
  > terraform workspace show
  default
  ```

- 그리고 S3 bucket을 보면 key에 지정한 것과 같이 `workspaces-example/terraform.tfstate`라는 파일이 생성된 것을 확인할 수 있다.

- 이제 example1이라는 새로운 workspace를 생성해보자.

  ```sh
  ❯ tf workspace new example1
  Created and switched to workspace "example1"!

  You're now on a new, empty workspace. Workspaces isolate their state,
  so if you run "terraform plan" Terraform will not see any existing state
  for this configuration.
  ```

- 이 상태에서 `terraform plan`을 수행하면 하나의 EC2 instance를 생성할 것이라고 나타난다.  
  이는 각 workspace에 있는 state file들이 서로로부터 격리되어 있기 때문이다. 기존에 EC2 instance를 생성했던 workspace는  
  default였고, 지금 있는 workspace는 example1이기 때문이다.

- 이 상태에서 `terraform apply`를 수행하면 새로운 EC2 instance가 하나 만들어진다.

- Workspace들은 `terraform workspace list` 명령어로 확인할 수 있고, 다른 workspace로 이동하려면  
  `terraform workspace select <workspace name>`을 수행하면 된다.

- 동일한 작업을 example2 workspace를 생성하고 수행해보자.

- 이렇게 동작하는 방식을 확인하기 위해 S3 bucket을 확인해보면, 최상단에 `env:` 라는 폴더가 생성되어 있다.  
  그리고 이 안에는 `example1`, `example2` 폴더가 생성되어 있다.

  ```
  |-- env:
  |   |-- example1
  |   |   |-- workspaces-example
  |   |   |   |-- terraform.tfstate
  |   |-- example2:
  |   |   |-- workspaces-example
  |   |   |   |-- terraform.tfstate
  ```

- 즉 이렇게 workspace마다 자신의 state file을 저장하고 있음을 알 수 있다.

- Terraform workspace는 이미 배포된 인프라에는 변경 사항을 적용하지 않고 코드를 리팩토링하는 상황 등에 유용하게 활용될 수 있다.  
  추가적으로 `terraform.workspace` 표현식을 활용해 인프라를 다르게 구성할 수도 있다.  
  아래 예시 코드는 workspace가 default일 때는 `t2.medium`을, 아닐 때는 `t2.micro`를 배포하도록 구성되어 있다.

  ```tf
  resource "aws_instance" "example" {
    ami           = "ami-0fb653ca2d3203ac1"
    instance_type = terraform.workspace == "default" ? "t2.medium" : "t2.micro"
  }
  ```

- 이렇게 Terraform workspace는 코드의 다른 버전들을 쉽게 배포하고 제거하는 용도로 사용될 수 있지만, 아래의 단점들이 존재한다.

  - State file들이 동일한 S3 bucket(즉, 동일한 backend)에 저장된다. 이는 곧 모든 workspace가 S3 bucket에 접근하기 위해  
    동일한 인증 및 접근 제어를 가질 것임을 의미하고, 이는 곧 workspace가 환경 분리에 부적합하다는 것을 의미한다.

  - Workspace는 `terraform workspace` 명령을 수행하지 않는 한 코드에서 확인할 수 없다. 코드만 봐서는 해당 코드에 관려된  
    인프라가 몇 개의 workspace에 배포되어 있는지 알 수 없다.

  - 위 두 가지를 합하면 여러 가지의 잘못된 상황을 야기하게 된다. 예를 들어, 실수로 개발 환경이 아닌 상용 환경에 `terraform destroy`를  
    수행하는 등 실수를 할 수 있다.

- 이러한 단점들 때문에 환경을 완전히 격리시키는 데에 Terraform workspace는 적합하지 않다.  
  완전한 환경 분리를 위해서는 바로 다음에 살펴볼 file layout을 사용하는 것이 좋다.

### Isolation via File Layout

- 환경 간의 완벽한 격리를 위해서는 아래의 내용들을 수행해야 한다.

  - Terraform configuration file을 환경별로 다른 폴더에 저장한다.  
    예를 들어 개발 환경의 인프라를 위한 코드는 _dev_ 폴더에, 상용 환경의 인프라를 위한 코드는 _prod_ 폴더에 저장한다.

  - 각 환경에 별도의 backend를 지정해 서로 다른 인증 메커니즘과 접근 제어를 지정한다.

- 위와 같은 접근법을 사용하면 폴더부터 어떤 환경의 인프라인지를 알 수 있게 된다.

- 추가적으로 환경 분리에 이어 "컴포넌트" 단위로 Terraform configuration file을 분리할 수도 있다.

  ![picture 2](/images/TFRU_13.png)

- 각 컴포넌트 파일에 있는 Terraform configuration file들은 아래와 같다.

  - `variables.tf`: Input variable 정의
  - `outputs.tf`: Output variable 정의
  - `main.tf`: Resource, data source 정의

- 위의 3개 파일은 널리 사용되는 컨벤션이며, 추가적으로 아래의 파일들도 자주 사용된다.

  - `dependencies.tf`: 모든 data source 정의
  - `providers.tf`: 모든 provider 정의
  - `main-xx.tf`: `main.tf` 파일이 너무 길어닐 때 `main-iam.tf` 등과 같이 리소스별로 분리

- 이렇게 여러 개로 디렉토리를 분리하면 각 디렉토리에서 `terraform apply` 등을 수행해야 한다는 단점이 있지만,  
  Terragrunt의 `run-all` 명령을 수행하면 한 번에 처리할 수 있다.

---
