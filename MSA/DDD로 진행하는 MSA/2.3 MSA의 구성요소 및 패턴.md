# MSA 구성 요소 및 패턴

- MSA 역시 검증된 아키텍쳐 스타일, 패턴이 존재한다.  
  개발자의 입장에서 마이크로서비스 시스템을 구현하기 위해 밟아야할 단계들을 순서대로 살펴보자.

- 우선은 `인프라가 구축`되어야 하고, 그 위에 `미들웨어`가 올라가고, 미들웨어 위에서 `애플리케이션이 동작`해야 한다.  
  따라서 `인프라`, 미들웨어 영역을 대신하고 있는 `플랫폼`, 그리고 `애플리케이션` 순으로 살펴보자.

- 먼저 클라우드 인프라 패턴이라고도 부를 수 있는 클라우드 인프라 영역의 구성요소를 살펴보자.

<table>
    <tr>
        <td>패턴 유형</td>
        <td>설명</td>
    </tr>
    <tr>
        <td>인프라 구성요소</td>
        <td>마이크로서비스를 지탱하는 하부구조 인프라를 구축하는 데 필요한 구성요소</td>
    </tr>
    <tr>
        <td>플랫폼 패턴</td>
        <td>인프라 위에서 마이크로서비스의 운영과 관리를 지원하는 플랫폼 차원의 패턴</td>
    </tr>
    <tr>
        <td>애플리케이션 패턴</td>
        <td>마이크로서비스 애플리케이션을 구성하는 데 필요한 패턴</td>
    </tr>
</table>

<hr/>

<h2>1. 인프라 구성요소</h2>

- IT에서 `인프라`라는 단어의 의미는 Enterprise IT 환경을 운영하고 관리하는 데 필요한 근간이 되는 하드웨어,  
  소프트웨어, 네트워킹 구성요소, 운영체제, 데이터 스토리지 등을 모두 포괄한다.  
  클라우드 환경에서는 이러한 인프라 구성요소들이 모두 가상화되어 제공된다.

<h3>온프레미스 vs 클라우드 환경</h3>

- AWS, GCP, Azure 등의 클라우드 서비스는 시스템의 자원 구성, 할당, 관리, 모니터링 등을 모두 제공하여  
  일련의 설정 작업들을 몇 번의 클릭만으로 처리할 수 있게 해준다.

- 이러한 환경에서 Architect가 해야하는 일은 가장 먼저 **맨 하부의 시스템의 기반이 되는 인프라 구축** 이다.  
  물론 이 과정에서 온프레미스 환경을 선택해도 된다. 하지만 가상화 장치 없이 온프레미스 환경의 장비들로 마이크로서비스  
  애플리케이션을 구동한다면 각 마이크로서비스마다 베어 메탈 장비를 구축해야 하고, 이는 당연히 인프라의 유연한  
  확장/축소를 기대하기 힘든 결과를 낼 것이다.

- 만약 가상 인프라 환경을 사용하기로 결정했다면, 그다음으로 가장 먼저 고려할 사항은 **VM 제품과 컨테이너 기반 제품 중 하나를 선택**  
  하는 것이다. 이 둘의 차이점을 알아보자.

<h3>VM, Container</h3>

- 우선, VM은 하이퍼바이저(Hypervisor)라는 소프트웨어를 이용해 하나의 시스템에서 여러 개의 OS를 사용하는 기술이다.  
  반면에 컨테이너는 하이퍼바이저 없이 컨테이너 엔진을 사용해 가상의 격리된 공간을 생성한다.

- 이 둘의 차이점은 Guest OS의 유무로 판단할 수 있는데, VM의 경우 Guest OS는 Host OS와 라이브러리(애플리케이션) 사이에  
  Hypervisor와 함께 위치하지만, 컨테이너의 경우에는 Docker Engine만이 Host OS와 라이브러리 사이에 위치한다.

- Guest OS를 사용하는 VM에는 운영체제 패치 설치나 관련 라이브러리 설치와 같은 오버헤드가 지속적으로 발생한다.  
  따라서 **마이크로서비스 같은 작은 서비스를 패키징하고 배포하기에는 컨테이너가 더 적합** 하다.

- 가장 대표적인 컨테이너 기수로는 필요한 라이브러리나 실행 파일을 여러 개의 Layer로 된 Image로 추가하거나 변경할 수 있는  
  Docker가 있다.

- Docker Container는 아래와 같은 계층으로 구성된다.

  - Image Layer 3 (Application)
  - Image Layer 2 (Runtime)
  - Image Layer 1 (OS)
  - Base Image (Base RHEL)

- Docker Container의 이점은 아래와 같다.

  - 이식성: 어떠한 호스트 커널이나 플랫폼 버전에 관계없이 Docker만 실행할 수 있으면 사용 가능하며 동일하게 동작된다.
  - 신속성: 크기가 작고 가볍기에 빠르게 배포가 가능하며, 문제 발생 시 수정할 필요 없이 새로 기동하면 된다.
  - 재사용성: 동일한 환경을 재사용해서 쉽게 설정 가능하기에 개발, 테스트, 스테이징, 프로덕트 환경을  
    동일한 환경으로 구축하기가 쉽다.

- 결론적으로 마이크로서비스와 같이 가변적이고 유연한 속성을 갖추기 위해서는 Container 기반의 아키텍쳐가 더욱 어울린다.

<h3>Container Orchestration</h3>

- 컨테이너 기술을 사용할 때에는 컨테이너를 관리하기 위한 기술 또한 필요하다.  
  컨테이너가 많아지면 그에 따라 컨테이너의 자동 배치 및 복제, 장애 복구, 확장 및 축소, 컨테이너 간의 통신,  
  로드 밸런싱 등의 컨테이너 관리를 위한 기능이 필요해진다.

- 이러한 기술을 Container Orchestration이라 하며, 이를 위한 도구로는 Docker Swarm, Apache Mesos 등이 있다.  
  최근에는 Google이 공개한 Kubernetes가 큰 인기를 끌고 있다.

- Kubernetes 대시보드를 보면 컨테이너 배포의 기본 단위에 해당하는 Pod, Deployment, Replica Set 등의  
  정보를 확인하고 설정할 수 있다. Kubernetes는 아래와 같은 주요 기능들을 제공한다.

  - Automatic Binpacking: 각 컨테이너가 필요로 하는 CPU와 메모리를 K8s에 요청하면 컨테이너를 노드에 맞춰 자동 배치한다.
  - Self-healing: 컨테이너에 대해 health check를 수행하여 실패한 경우 자동으로 교체하고 re-scheduling 한다.
  - Horizontal Scaling: 일정 CPU 및 메모리 사용량을 초과하면 자동으로 확장한다.

- 또한 Kubernetes는 일부 마이크로서비스 운영/관리 패턴을 자체적으로 내장하고 있기도 하다.

<hr/>

<h2>마이크로서비스 운영과 관리를 위한 플랫폼 패턴</h2>

- 애플리케이션이 실제로 구동되는 인프라 환경을 결정했다면 그 다음으로 선택한 인프라 환경 위에서  
  애플리케이션을 운영하고 관리하는 환경을 구성하는 방법을 생각해야 한다.  
  특히 **애플리케이션을 빌드하고 인프라에 배포할 수 있는 환경** 이 중요하다.  
  왜냐하면 마이크로서비스 환경을 구성하는 수많은 마이크로서비스들을 하나하나 빌드하고 배포한다면  
  굉장히 비효율적이고 큰 혼란을 가져올 것이기 때문이다.

 <h3>개발 지원 환경: DevOps 인프라 구성</h3>

- 필요한 요소는 마이크로서비스를 빌드하고 테스트한 뒤 배포할 수 있게 도와주는 개발환경인 DevOps 환경이다.  
  DevOps는 개발과 운영이 분리되지 않은 개발 및 운영을 병행할 수 있는 조직 또는 그 문화를 일컫는데,  
  여기서는 협의의 의미로 개발과 운영을 병행 가능하게끔 높은 품질로 소프트웨어를 빠르게 개발하도록 지원하는  
  빌드, 테스트, 배포를 위한 자동화 환경을 말한다.

- 그럼 자동화 환경이 있기 전의 수동 배포 절차를 살펴보자.

  - (1) 개발자가 개발 환경에서 애플리케이션을 완성하고, 컴파일하고 수동 테스트 후 발생한 오류를 수정한 뒤 스테이징 환경에 배포한다.
  - (2) 운영 환경 배포 전에 스테이징 환경에서 다시 테스트한다. 그러다 예상치 못한 오류를 발견하면 다시 첫 환경인 개발 환경으로 돌아가  
    오류를 수정한 뒤 다시 스테이징 환경에서 테스트를 수행한다.
  - (3) 위 과정에 무사히 끝나면 배포 승인을 받고 배포 담당자가 애플리케이션을 운영 환경에 배포한다.

- 위와 같은 수동 빌드/배포 과정에는 정말 많은 시간이 소모되며, 대부분의 경우에는 시스템 사용률이 낮은 새벽 시간대에 시스템을  
  장시간 멈추고 배포 작업을 진행하는 경우가 많다. 당연히 이러한 환경에는 비즈니스 민첩성이 높을 수가 없다.  
  특히 여러 개의 마이크로서비스를 배포해야 하는 환경에서는 배포가 잦을 수 밖에 없기에 자동화가 절실하다.

- 마이크로서비스는 당연히 각 마이크로서비스마다 Repository를 다르게 가지기에 각 서비스마다 각각의  
  CI/CD 파이프라인이 구축되어 자동화가 진행되어야 한다.

<h3>마이크로서비스 생태계와 운영 관리 요소의 탄생</h3>

- Netflix가 스트리밍 산업을 한지 얼마 되지 않아 스트리밍 데이터베이스 스토리지가 손실되는 대규모 서비스 장애를 겪었다.  
  이를 계기로 Netflix는 한 덩어리의 모노리스 시스템에서 마이크로서비스 기반의 시스템으로 전환하는 작업을 시작한다.  
  이때 선택한 것은 AWS EC2 이다.

- 그러나 클라우드 기반에서 마이크로서비스로 전환하는 것은 쉽지 않았다. 우선 애플리케이션이 한 덩어리일 때 발생하지 않았던  
  여러 문제점들이 불거졌다. 전체 서비스를 여러 개의 서비스로 분산 구성했을 때 한 서비스에서 발생한 장애가 다른 서비스로  
  전파된다거나 여러 서비스에 분산된 로그를 관리해야하는 불편함, 서비스가 하나로 동작하지 않아 시스템의 일부 기능이  
  동작하지 않아도 그것을 알아채지 못하고 장애가 방치되는 문제들이 발생했다.

- 이러한 문제들을 해결하기 위해 Netflix는 다양한 서비스와 도구를 개발하게 되었으며, 이를 오픈소스로 공개했는데,  
  이것이 바로 Netflix OSS 이다. Netflix OSS에는 여러 마이크로서비스 간의 Routing과 Load Balancing을 위한  
  Zuul과 Ribbon, 모니터링을 위한 Hystrix, 서비스 등록을 위한 Eureka 등이 포함되어 있다.

<h3>마이크로서비스 관리/운영 패턴</h3>

- 마이크로서비스 구축 시 발생하는 문제는 주로 시스템을 여러 개의 서비스로 구성하기 때문에 발생하는 문제이다.  
  Netflix가 이 문제를 해결하는 데 크게 기여했는데, Netflix OSS는 Netflix가 마이크로서비스를 개발하고  
  운영하면서 생긴 노하우를 다른 사람들도 쉽게 사용할 수 있도록 공유한 오픈소스이다. 이는 마이크로서비스 생태계에  
  크게 도움이 되었고, 특히 마이크로서비스 관리와 운영을 지원하는 전형적인 마이크로서비스 애플리케이션 패턴으로  
  자리잡았다. 예를 들어 API Gateway, Service Discovery, Monitoring, Tracing 등이 다수의  
  마이크로서비스를 관리 및 운영하기 위한 플랫폼 패턴으로서 Netflix에서 소스 코드를 공개하고 나서 패턴으로  
  정착되고 나중에 이러한 패턴을 적용한 다른 여러 도구들과 오픈소스들이 생겨나는 밑거름으로 작용했다.

- 또한 Netflix OSS를 더 쉽게 쓸 수 있도록 Spring에서는 기존의 Spring Boot Framework에서 잘 돌아갈 수  
  있도록 Netflix OSS Module을 Spring Framework로 감싸서 Spring Cloud라는 이름으로 발표했다.  
  이를 통해 Spring Boot와 Spring Cloud는 마이크로서비스를 개발하기 위한 가장 대중적인 프레임워크로  
  자리매김했다. Spring Boot + Spring Cloud의 조합을 사용하면 마이크로서비스 애플리케이션의 운영 환경을  
  쉽게 구축할 수 있다.

<h3>Spring Cloud: Spring Boot + Netflix OSS</h3>

- Spring Cloud를 이용한 마이크로서비스 구조에 대해 살펴보자.

1. 모든 마이크로서비스는 인프라에 종속되지 않도록 데이터베이스, 파일 등에 저장된 환경 설정 정보를  
   형상 관리 시스템에 연계된 Configuration Service에서 가져와 설정 정보를 주입한 후 클라우드  
   인프라의 개별 인스턴스로 로딩된다.

2. 로딩과 동시에 Service Registry에 자신의 서비스명과 클라우드 인프라로부터 할당받은 물리적 주소를  
   매핑해서 등록한다.

3. 클라이언트가 API Gateway를 통해 마이크로서비스에 접근하고, 이때 API Gateway는 적절한 Routing  
   및 부하 관리를 위한 Load Balancing을 수행한다.

4. 또한 API Gateway에서 클라이언트가 마이크로서비스에 접근하기 위한 주소를 알기 위해 Service Registry를  
   검색을 통해 서비스의 위치를 가져온다.

5. 동시에 API Gateway는 클라이언트가 각 서비스에 접근할 수 있는 권한이 있는지를 판단하기 위해  
   Authentication Service와 연계하여 인증/인가 처리를 수행한다.

6. 이러한 모든 마이크로서비스 간의 호출 흐름은 Monitoring Service와 Tracing Service에 의해 모니터링되고  
   추적된다.

- 위의 흐름이 MSA의 주요 아키텍쳐 패턴이기에 AWS, Azure, GCP 등에서도 이를 자체 기능 또는 과금되는 별도 서비스로  
  제공한다. 이어서 널리 사용되는 MSA 패턴 중심으로 하나씩 자세히 살펴보자.

<h3>Service Registry, Service Discovery 패턴</h3>

- Frontend 클라이언트가 여러 개의 Backend 마이크로서비스를 어떻게 호출해야 할까?  
  또한 Scale-Out를 통해 인스턴스가 여러 개로 복제되었다면 어떻게 부하를 적절히 분산할 수 있을까?

- 위 질문들을 위한 패턴이 `Service Discovery Pattern`이다. 클라이언트가 여러 개의 마이크로서비스를  
  호출하기 위해서는 최적 경로를 찾아주는 Routing 기능과 적절한 부하 분산을 위한 Load Balancing 기능이  
  제공되어야 한다. Netflix OSS의 경우, Routing은 Zuul이, Load Balancing은 Ribbon이 담당한다.

- 라우터는 최적 경로를 탐색하기 위해 서비스 명칭에 해당하는 IP 주소를 알아야 한다.  
  그런데 이러한 라우팅 정보를 클라이언트가 가지고 있으면 클라우드 환경에서 동적으로 변경되는 Backend의  
  유동 IP 정보를 매번 전송받아 변경해야 한다. 따라서 제3의 공간에서 이런 정보를 관리하는 것이 좋다.

- 즉 Backend 마이크로서비스 서비스의 명칭과 유동적인 IP 정보를 매핑해서 보관할 저장소가 필요한 것이다.  
  Netflix OSS의 Eureka가 이 기능을 담당하고, 이러한 패턴을 `Service Registry Pattern`이라 한다.

- 우선 각 서비스 인스턴스가 로딩될 때 자신의 서비스명과 할당된 IP 주소를 Registry Service에 등록한다.  
  그런 다음, 클라이언트가 해당 서비스명을 호출할 때 Router가 Registry Service를 검색해 해당 서비스의  
  이름과 매핑된 IP 정보를 확인한 후 호출한다. 이 Registry Service는 모든 마이크로서비스 인스턴스의  
  주소를 알고 있는 서비스 매핑 저장소가 된다. 모든 마이크로서비스가 처음 기동할 때 자신의 위치 정보를  
  저장하고 서비스가 종료될 때 위치 정보가 삭제된다.

- Service Registry에는 업무 처리를 위한 마이크로서비스 뿐만 아니라 관리와 운영을 위한 기반 서비스의  
  주소도 함께 보관한다. 예를 들면 Configuration Service, Monitoring, Tracing Service도 모두  
  이름을 가지고 있기에 주소를 가지고 있어야 한다.

- 실제로 Spring Eureka로 구현된 Registry Service를 보면, 서비스명과 IP 주소 및 포트 정보가  
  매핑된 것을 확인할 수 있다. 다수의 인스턴스가 하나의 서비스명으로 등록 될 때 다수의 IP 주소와 포트 정보가  
  매핑되고, Router는 이 정보를 질의해서 Load Balancing도 할 수 있다.

<h3>서비스 단일 진입을 위한 API Gateway 패턴</h3>

- 여러 클라이언트가 여러 개의 서버 서비스를 각각 호출하게 된다면 매우 복잡한 호출 관계가 만들어질 것이다.  
  이러한 복잡성을 통제하기 위한 방법 중 하나가 API Gateway이다.

- API Gateway는 다양한 클라이언트가 다양한 서비스에 접근하게 할 수 있도록 단일 진입점을 만들어놓는다.  
  무조건 단일 진입점을 먼저 거치게 한다면, 다른 유형의 클라이언트에게 서로 다른 API 조합을 제공할 수도 있고,  
  각 서비스에 접근할 때 필요한 인증/인가 기능을 한 번에 처리할 수 있다. 또한 정상적으로 작동하던 서비스에  
  문제가 생겨 응답 지연이 발생하면 정상적인 다른 서비스로 요청 경로를 변경하는 기능을 구현할 수도 있다.

- 이러한 서비스 흐름 제어를 위한 서비스 라우팅 기능은 소프트웨어, 하드웨어 둘 다로 구현할 수 있는데,  
  소프트웨어로 구현할 경우 API Gateway가 Application Level의 Routing을 수행한다.  
  또한 여러 인스턴스로 부하를 분산하는 Load Balancing도 수행하고, Routing시 필터를 두어  
  Routing 전과 후에 각각 수행되는 선행, 후행처리 및 에러처리를 손쉽게 할 수 있다.

- 정리하자면, API Gateway는 다른 서비스들과 연계해서 아래와 같은 기능들을 제공한다.

  - Registry Service와 연계한 Dynamic Routing, Load Balancing
  - 보안: 권한 서비스와 연계한 인증/인가
  - Logging Service와 연계한 로깅
  - Metrics(에러율, 평균/최고 지연시간, 호출 빈도 등)
  - Tracing Service와 연계한 서비스 추적
  - Monitoring Service와 연계한 장애 격리

- 이러한 API Gateway Pattern은 Spring API Gateway Service로 간단한 어노테이션만으로  
 손쉽게 적용할 수 있다.
<hr/>

<h3>BFF 패턴</h3>

- 최근에는 PC 뿐만아니라 다양한 모바일 장치를 사용하기에 다양한 클라이언트를 고려해야 한다.  
  이처럼 다양한 클라이언트를 위해서는 특화된 처리를 위한 API들의 조합이나 처리가 필요하다.  
  이를 위한 해결 방법으로 BFF(Backend for Frontend) 패턴이 있다.

- BFF 패턴은 API Gateway와 같은 진입점을 하나로 두지 않고, Frontend의 유형에 따라  
 각각 두는 패턴이다. 웹을 위한 API Gateway, 모바일을 위한 API Gateway 등과 같이  
 클라이언트의 종류에 따라 최적화된 처리를 수행할 수 있게 구성할 수 있다.  
 이로써 모바일을 위한 API만 선택해서 제공하거나 웹을 위한 API만 적절하게 제공할 수 있다.  
 또한 각 Frontend에 대한 처리만 수행하는 BFF를 가장 앞에 놓고, 그 이후에 통합적인  
 API Gateway를 두어 공통적인 인증/인가, 로깅 등의 처리를 하는 구조로 구성할 수도 있다.
<hr/>

<h3>외부 구성 저장소 패턴</h3>

- 마이크로서비스를 구현하면, 재배포를 할 때 데이터베이스 설정 정보 등 애플리케이션의 수행에 필요한  
  설정값들이 변경될 수 있다. 또한 설정 정보 자체가 바뀌면 만약 여러 마이크로서비스가 동일한 구성 정보를  
  사용하는 경우에도 일일이 변경하기가 어렵고, 실수가 발생할 수도 있다.  
  따라서 마이크로서비스가 사용하는 자원의 설정 정보를 쉽고 일관되게 변경 가능하도록 관리할  
  필요가 있다,

- 이를 위한 방법이 외부 저장소 패턴인데, 외부 저장소는 각 마이크로서비스의 외부 환경 설정 정보를  
  공동으로 저장하고 가지고 있는 백업 저장소이다.

- 클라우드에서 운영되는 애플리케이션은 특정한 배포 환경에 종속된 정보를 코드에 두면 안된다.  
  왜냐하면 이런 정보들을 코드에 두면 배포 환경이 변경됐을 때 애플리케이션 또한 변경해야하기 때문이다.  
  이렇게 분리해야할 정보로는 DB 연결 정보, 배포 시 변경해야 할 호스트명, 백엔드 서비스의 연결을 위한  
  리소스 정보 등이 있다.

- 예를 들어, Spring Cloud Config을 사용하면 이러한 환경 정보를 코드에서 분리하고  
  Configuration Service를 통해 Runtime시에 주입되게 할 수 있다.  
  환경 정보는 Git과 같은 repository에 보관하고 Configuration Service는  
  해당 서비스가 특정 환경에 배포될 때 적절한 환경 정보를 가져와 해당 서비스에 주입한다.

- K8s는 이러한 외부 구성 저장소 패턴을 ConfigMap으로 제공한다.
<hr/>

<h3>인증/인가 패턴</h3>

- 여러 마이크로서비스 각각이 모두 인증/인가를 중복으로 구현한다면 매우 비효율적이다.  
  따라서 마이크로서비스가 인증/인가를 처리하기 위해 사용하는 패턴을 살펴보자.

<h4>중앙 집중식 세션 관리</h4>

- 기존 모노리스 방식에서 가장 많이 사용했던 방식은 서버의 세션에 사용자의 로그인 정보 및 권한 정보를  
  저장하고, 이를 통해 애플리케이션의 인증/인가를 판단하는 것이다. 그렇지만 마이크로서비스는 사용량에 따라  
  수평 확장이 될 수도 있고 Load Balancing처리가 되기에 세션 데이터가 유실될 수도 있다.  
  따라서 마이크로서비스는 각자의 서비스에 세션을 저장하지 않고 공유 저장소에 세션을 저장하고, 모든 서비스가  
  동일한 사용자 데이터를 얻게 한다. 세션 저장소로는 보통 Redis, MemCached를 사용한다.

<h4>클라이언트 토큰</h4>

- 익히 알고 있는 JWT 인증 방식이다. 세션은 중앙 서버에 저장되며 토큰은 클라이언트 측에서 보관한다.

<h4>API Gateway를 사용한 클라이언트 토큰</h4>

- 사용자 인증 프로세스는 토큰 인증 프로세스와 유사하다. 차이점은 API Gateway가 외부 요청의 입구로  
   추가된다는 것이다. 또한 인증/인가를 처리하기 위한 별도의 전담 서비스(Auth Service)를 만들어서  
   다른 서비스의 인증/인가 처리를 위임하도록 한다. 이렇게 Auth Service를 API Gateway와  
   연동해서 이용하면 각 리소스 서비스가 자체적으로 인증/인가를 처리하지 않고 업무 처리에 집중할 수 있다.  
   순서는 아래와 같다.

  1. 클라이언트가 리소스 서비스에 접근을 요청하면 API Gateway는 인증 서비스에게 전달한다.
  2. 인증 서비스는 해당 요청이 인증된 사용자가 보낸 것인지를 검증하는 인증 단계와, 해당 리소스에 대한 접근  
     권한이 있는지를 파악하는 인가 단계를 모두 진행하고, 모두 확인하고 나면 리소스 접근을 허용하기 위한  
     AccessToken을 지급한다.
  3. 클라이언트는 AccessToken과 함께 다시 접근을 요청한다.
  4. 각 리소스는 이러한 요청이 AccessToken을 포함하고 있는지를 판단해서 리소스에 대한 접근을 허용한다.
  <hr/>

<h3>장애 및 실패 처리를 위한 Circuit Breaker 패턴</h3>

- 여러 개의 서비스로 구성된 시스템에서는 한 서비스에 장애가 생겼을 때 다른 서비스가 영향을 받을 수 있다.  
  이때, 장애가 발생한 서비스를 격리해서 유연하게 처리할 수 있는 방법이 필요한데, 이를 위한 한 가지 방법이  
  서킷 브레이커 패턴이다.

- 서비스의 수가 많아지면 분명한 장점도 있지만 단점 또한 분명히 존재한다. 예를 들면 사용자가 접하는 전체 시스템은  
  정상적인데 특정 기능을 사용하려 하면 즉각 에러가 발생하지도 않고 한참 동안 대기하는 상황이 발생할 수도 있다.  
  사용자 입장에서는 이같은 상황이 장애인지 판단도 되지 않으며 단순히 시스템이 느려졌다고 판단할 수도 있다.  
  이러한 상황은 정상적인 서비스가 장애가 발생한 서비스에 의존해서 서비스를 제공할 때 문제가 발생하는 상황으로서  
  장애가 다른 서비스로 *전이*된 상태이다. 이러한 일을 막기 위해 특정 서비스에 문제가 생겼을 때 자연스럽게  
  다른 정상적인 서비스로 요청 흐름이 변경되도록 해야 한다. 이렇게 하기 위해서는 서비스 상태를 실시간으로 관리해서  
  시각화하고 모니터링할 수 있어야 하고, 특정 서비스에서 장애가 감지되면 장애가 다른 서비스로 전이되지 않게 하는  
  방법이 반드시 필요하다.

- 간단한 흐름을 살펴보자. Service A가 Service B를 호출해서 자신의 서비스를 제공하는데, Service B에서  
 장애가 발생하면 동기 요청(Request)의 특성상 Service A는 계속해서 Service B의 응답을 기다리게 된다.  
 이 경우, 사용자 입장에서는 Service A도 장애가 발생한 것처럼 느껴진다. 서킷 브레이커 패턴은 이와 같은  
 경우에 Service B의 호출에 대한 연속 실패 횟수가 임계값을 초과하면 이후에 Service B를 호출하려는 모든  
 시도를 즉각 실패처리 하게 만든다. 그리고 Fallback 메소드를 지정해 두면 장애가 발생했을 때 Fallback  
 메소드가 자연스럽게 격리를 진행하게 된다. 그럼 사용자는 특정 서비스에 장애가 발생했는지 눈치채지 못하고  
 시간이 흘러 장애가 복구되었을 때 다시 호출을 정상화하면 된다.
<hr/>

<h3>Monitoring, Tracing Pattern</h3>

- 위에서 Circuit Breaker Pattern이 잘 작동하게 하기위해 기본적으로 필요한 것은 *서비스 장애의 감지*이다.  
  이를 감지하려면 각 마이크로서비스의 장애를 실시간으로 감지해야 하고, 서비스 간의 호출이 어떤지 알아야 한다.  
  즉, 모니터링하고 추적하는 패턴이 필요하다. Spring Cloud에서는 Hystrix라는 라이브러리를 제공하고,  
  이 라이브러리가 배포된 서비스를 모니터링할 수 있는 Hystrix Dashboard를 제공함으로써 마이크로서비스의  
  요청을 실시간으로 모니터링할 수 있다.

- 다음으로 알아볼 것은 분산 추적 서비스이다. 모니터링과 함께 각 서비스 트랜잭션의 호출을 추적하면  
 마이크로서비스의 운영에 매우 유용하다. 트위터의 Zipkin과 같은 대시보드를 사용하면 분산된 서비스 간의  
 호출이나 지연 구간별 장애 포인트를 확인할 수 있다.
<hr/>

<h3>중앙화된 로그 집계 패턴</h3>

- 마이크로서비스의 로그 관리 방법에 대해 알아보자. 마이크로서비스는 사용량에 따라 탄력적으로 변화하면서  
  언제든지 인스턴스가 생성/삭제되는 과정에서 로컬 로그가 초기화될 가능성이 충분히 있다.

- 로그는 Event Stream으로 처리하여, 시작과 끝을 고정하지 않고 서비스가 실행되는 동안 계속 흐르는 하나의  
  흐름(Stream)처럼 처리해야 한다. 그리고 서비스는 스트림의 전달이나 저장에 절대 관여하면 안된다.  
  왜냐하면 로그를 전달 및 저장하는 메커니즘 자체가 특정 기술 또는 인프라에 의존할 수 밖에 없고 이러한 메커니즘을  
  직접 마이크로서비스에 구현한다면 유연성이 그만큼 떨어지기 때문이다.

- 그래서 필요한 것이 중앙화된 로그 집계 패턴인데, 가장 먼저 서비스에서 발생한 이벤트 스트림 형태의 로그를  
  수집하고 살펴볼 도구가 필요하다. 대표적으로 많이 쓰이는 기술이 ELK Stack인데, ELK Stack은  
  `ElasticSearch`, `Logstash`, `Kibana`라는 3개의 오픈소스 프로젝트를 기반으로 데이터 분석 환경을  
  구성한 것이다. `ElasticSearch`는 분석 엔진이고, `Logstash`는 서버측 로그 집합기이다.  
  `Kibana`는 시각적으로 로그 내역을 보여주는 대시보드이다.

- ELK Stack을 이용하면 각 서비스 인스턴스의 로그를 집계해서 중앙에서 집중 관리할 수 있으며, 손쉽게 특정 로그를  
  검색 및 분석할 수 있다. 또한 특정 메시지가 로그에 나타나거나 특정 예외 상황이 발생할 때 운영자나 개발자에게  
  직접 통보하게 할 수도 있다.

- ELK Stack을 사용한 아키텍쳐의 예시를 보자. 각 서비스에 Logstash가 설치되어 각 로그를 수집해서 중앙 Redis에  
 보낸다. 또 다른 서비스에서는 ElasticSearch와 Kibana로 로그 중앙 관리 저장소와 대시보드 서비스를 각각  
 구축한다. 마이크로서비스에서 보낸 로그가 중앙 Redis에 쌓이면 Redis에서 중앙 관리 저장소에 로그를 보내고,  
 이 로그 저장소에 ElasticSearch Engine이 로그를 Indexing하고 해당 로그 정보가 Kibana Dashboard를 통해  
 보여진다. 중간 과정에 Redis Database가 있는 이유는 로그 스트림이 너무 몰리면 로그 저장소 서비스에도  
 성능 문제가 생기기 때문에 중간에 임시 저장소를 추가한 것이다.
<hr/>

<h3>Service Mesh Pattern</h3>

- 초창기 MSA 기술인 Netflix OSS, Spring Cloud 기반의 서비스를 구축 및 운용할 때의 문제점은  
  API Gateway, Service Registry, Configuration Service와 같이 운영 관리를 위한 여러 개의  
  기반 서비스들을 별도로 각각 만들어야 한다는 번거로움과 더불어 업무 처리 마이크로서비스에 Spring Cloud를  
  사용하기 위한 라이브러리를 비즈니스 로직과 함께 탑재해야 한다는 점이었다. 기능 구현에 집중해야 하는  
  마이크로서비스 입장에서 이러한 코드까지 관리 및 운영해야 한다면 번거로울 수밖에 없다.

- 또한 Spring Cloud는 Java기반이기에 다른 언어로는 이용할 수 조차 없었다.

- 그래서 최근에는 MSA 문제 영역 해결을 위한 기능(서비스 탐색, 서킷 브레이크, 추적, 로드 밸런싱 등)을  
  **비즈니스 로직과 분리해서** 네트워크 인프라 계층에서 수행하게 하는 서비스 메시(Service Mesh)패턴이 선호된다.  
  Service Mesh는 인프라 레이어로서 서비스 간의 통신을 처리하며 앞서 언급한 여러 문제 해결 패턴을 포괄한다.

- Service Mesh Pattern의 대표적인 구현체로는 Google의 `Istio`가 있다.  
  `Istio`는 애플리케이션이 배포되는 컨테이너에서 완전히 격리되어 별도의 컨테이너로 배포되는 Sidecar Pattern을  
  적용해서 서비스 디스커버리, Routing, Load Balancing, 모니터링, 보안, 추적 등의 기능을 제공한다.

> Sidecar Pattern은 모든 서비스 컨테이너에 추가로 사이드카 컨테이너가 배포되는 패턴으로,  
>  각 서비스를 연계할 때 한 서비스가 다른 서비스를 직접 호출하지 않고 Sidecar인 Proxy를 통해 연계해서  
>  개발자가 별도의 작업 없이 관리 및 운영에 대한 서비스 등을 적용할 수 있다.

- 기본적으로 Istio는 K8s에 탑재되어 이러한 서비스 메시 기능을 지원한다. 앞서 말했듯이 이전에는  
  Spring Cloud와 Netflix OSS의 조합을 사용하려면 Spring Cloud로 각 서비스를 먼저 구축하고 마이크로서비스  
  애플리케이션 자체도 코드 내부에 Spring Cloud의 사용을 위한 클라이언트 코드가 탑재되어 있어야 했다.  
  하지만 서비스 메시를 적용하는 경우에는 마이크로서비스마다 함께 배포되는 Sidecar Proxy에 운영 관리를 위한 기능이  
  별도로 담겨있기 때문에 마이크로서비스는 순수 비즈니스 로직에만 집중할 수 있다.

- Istio는 아래와 같이 Spring Cloud, Netflix OSS에서 제공했던 대부분의 기능을 제공함과 동시에 차별점도 가진다.

<h4>주요 기능</h4>

- Traffic Management: Dynamic Routing, Load Balancing
- Security: TLS, 인증/인가/암호화
- 관측성: Metrics, Tracing, Logging

<h4>차별점</h4>

- 애플리케이션 코드의 변경이 거의 없다. Spring Cloud + Netflix OSS 기반은 비즈니스 로직과 함께 코드로  
  표현되어야 하지만 Istio는 완전히 Sidecar로 격리되며 yaml과 같은 설정 파일에 의해 정의된다.
- Polyglot Application도 지원한다. Spring Cloud + Netflix OSS 기반은 Java기반의 언어만 지원한다.
- Istio는 K8s와 완벽하게 통합된 환경을 지원한다.
<hr/>

<h2>애플리케이션 패턴</h2>

- 이제는 실제로 개발자가 구현해야 할 애플리케이션 영역으로 넘어와서 마이크로서비스를 구성하기 위한 패턴을 보자.  
  물론 아키텍쳐와 마찬가지로 유연성과 확장성, 독립성을 염두에 두고 설계해야 한다.

- 먼저 Frontend를 구성하기 위한 패턴을 보자. 위의 것들은 Backend의 서비스를 여러 개의 마이크로서비스로 구성하는  
  경우였는데, 그렇다면 실제 사용자와의 접점이 되는 Frontend는 어떻게 구성해야 할까?

* 단순한 방법은 예전처럼 단일 모노리스 애플리케이션으로 구성하는 방법이다.  
  모노리스 프론트엔드는 백엔드의 여러 API를 호출하고 조합한 후 화면으로 구성해서 보여준다.  
  이 경우의 고민은 프론트엔드가 한 덩어리일 경우, 과연 마이크로서비스 기반 시스템의 장점인 서비스의 독립적인  
  변경과 배포가 가능할까 이다.

* 하나의 feature단위는 많은 경우에 백엔드와 프론트엔드의 연계로 구현된다. feature 하나가 새로 생겨 배포를 해야하는  
  상황을 가정해보자. 백엔드는 수정해서 하나의 서비스로 독립적으로 배포가 가능하지만, 프론트엔드는 덩어리이기 때문에  
  변경되지 않은 다른 기능들도 함께 빌드되고 배포해야 한다. 따라서 이전의 백엔드가 모노리스였을 때 겪었던 문제를(확장성, 독립성 부족)  
  프론트엔드의 모노리스 서비스도 겪을 수 밖에 없다.

<h3>UI Composite Pattern, Micro Frontend</h3>

- 위의 모놀리틱한 프론트엔드가 겪는 문제를 해결하기 위한 방안으로는 UI Composite Pattern과 Micro Frontend가 있다.  
  프론트엔드 또한 백엔드 마이크로서비스처럼 기능별로 분리하고 이를 조합하기 위한 frame 형태의 부모 창을 통해 각  
  프론트엔드를 조합해서 동작하게 한다. 이 부모 서비스는 틀만 가지고 있고, 실제 각 기능은 마이크로 프론트엔드의 각 조각이  
  구현하게 한다. 이 마이크로 프론트엔드들은 비즈니스 구현을 위해 여러 개의 백엔드 마이크로서비스 API를 호출한다.

- 이제 프론트엔드도 별도의 독립된 소스 레포지토리에서 작업이 가능하며, 이를 이용하여 독립적인 빌드 및 배포가 가능하다.

- 실제로 아마존의 메인 화면은 여러 개의 조각들로 구성되며, 각 조각은 여러 개의 마이크로 프론트엔드의 조합으로  
 서비스를 제공한다. 따라서 하나의 기능을 변경했을 때 이를 제공하는 마이크로 프론트엔드와 백엔드를 구성하는  
 마이크로서비스가 모두 변경되고 배포된다.
<hr/>

<h3>마이크로서비스 통신 패턴</h3>

- 다음으로 마이크로서비스 사이의 통신 방식을 알아보자.  
  프론트와 백엔드, 그리고 백엔드 간의 서비스 호출은 어떤 방법을 사용해야 할까?

<h4>동기 통신 방식</h4>

- 동기 호출 방식은 클라이언트에서 서버 측에 존재하는 마이크로서비스 REST API를 호출할 때 사용되는  
  기본 통신 방법이며, 다양한 클라이언트 채널 연계나 라우팅 및 로드 밸런싱을 원활하게 하기 위한 방법으로  
  중간에 API Gateway를 둘 수 있다.

- 프론트엔드에 웹, 앱의 2개가 있고,백엔드가 상품, 추천, 리뷰라는 3개의 마이크로서비스로 구성되어 있다고 하자.  
  이 둘 사이에는 단일 진입점의 역할을 해주는 API Gateway가 존재한다.

- 클라이언트에서 백엔드 서비스 호출에는 동기 호출 방식을 사용하는데, 백엔드 마이크로서비스 간의 호출에는 어떤 방법을  
  사용하면 좋을까? 즉, 예를 들어 추천 서비스가 상품 서비스와 리뷰 서비스를 호출한다면 API를 통해서만 호출해야 할까?

- 물론 가장 먼저 검토해야할 방법은 REST API 같은 동기식 호출이다.  
  동기(Synchronous)방식은 요청(request)을 하면 바로 응답(response)이 오는 방식을 말한다.

- 모바일 UI 고객에 주문 내역을 확인하기 위해 주문 서비스에 HTTP GET 요청을 보낸다면, 주문 서비스는 고객 정보를 확인하기 위해  
  고객 서비스에 GET 방식의 동기 호출을 수행한다. 그에 따라 바로 response가 오며, 성공 시 200 상태코드를 받아온다.  
  이처럼 요청을 하면 응답이 오는 직관적인 방식이기 때문에 동기 통신 방식은 가장 많이 쓰이고 구현하기 쉽다.  
  **하지만 호출을 받은 마이크로서비스에 장애가 생긴다면 요청을 보낸 서비스는 응답이 올 때까지 기다리게 되고,**  
  **응답이 오지 않으면 계속 기다리면서 재호출하게 된다.**

- 여러 서비스 간의 연계를 통해 업무를 처리하는 마이크로서비스 구조에서는 이 같은 상황에서 장애가 연쇄적으로 발생할 수 있다.  
  또 서비스가 다른 서비스를 호출해서 얻은 정보를 이용해 기능을 제공한다는 것은 해당 서비스 사이의 의존 관계가  
  높다는 것을 의미한다. 이러한 방식의 서비스 제공은 독자적인 마이크로서비스별로 비즈니스 기능 처리를 어렵게 한다.  
  따라서 장애의 파급 효과 및 의존 관계를 낮추기 위한 다른 통신 방법이 필요하다.

<h4>비동기 통신 방식</h4>

- 위 문제를 해결하기 위한 방식의 비동기(asynchronous) 호출 방식이다.  
  비동기 호출은 동기 호출처럼 응답을 기다리지 않는다. 그리고 이 방식은 메시지 기반으로 작동한다.  
  메시지를 보낸 다음 **응답을 기다리지 않고** 다음 일을 처리한다. 물론 보낸 결과가 어떻게 되었는지에 대한  
  응답을 받지 않으므로 동기 호출처럼 완결성을 보장할 수는 없다. 따라서 이를 보장하기 위한 메커니즘이 필요한데,  
  보통 Apache Kafka, RabbitMQ, ActiveMQ와 같은 Message Broker를 사용한다.

- 이러한 메커니즘에서는 `메시지를 보내는 생산자(producer)`와 `메시지를 가져와 처리하는 소비자(consumer)`가  
  서로 직접 접속하지 않고 Message Broker에 연결한다. Message Broker에 메시지를 전달하고, 자신의 일을  
  처리하면 Message Broker가 전송을 보장하게 된다. 그런데 여러 서비스에서 전달한 메시지를 처리하는 Message  
  Broker 자체에도 부하가 생길 수 있다. 이 경우 Message Broker는 메시지 처리 규모에 따라 확장이 가능하다.

- 이 방식은 Message Broker에 의해 중계되기에 서로 통신하는 서비스들이 물리적으로 동일한 시스템에 위치할  
  필요도 없으며, 서로 프로세스를 공유할 필요도 없다. 심지어 동일한 시간대에 동시에 동작하지 않아도 된다.  
  따라서 서비스 요구에 따라 확장 가능성을 보장해야하는 클라우드 플랫폼 환경에서 서비스가 다운됐을 때 또는 시스템을  
  더 확장해야 할 때 사용할 수 있는 매우 효과적인 방법이다.

- Apache Kafka, RabbitMQ외에 클라우드 vendor사에서 완전관리형으로 제공하는 서비스로  
 AWS SQS, SNS와 Azure Event Hub, Azure Event Grid등도 많이 사용된다.
<hr/>

<h3>저장소 분리 패턴</h3>

- 마이크로서비스를 독립적으로 수정 및 배포하기 위한 저장소 형태를 생각해보자.  
  기존 모노리스 시스템의 저장소는 통합 저장소이다. 즉, 애플리케이션 모듈은 분리하되 저장 처리는  
  모듈별로 격리하지 않고 다른 모듈에서의 호출을 허용하는 구조였다.

- 대부분의 모노리스 애플리케이션은 비즈니스 로직이 데이터베이스의 SQL 처리에 몰려있다.  
  이러한 구조를 데이터 중심 애플리케이션이라 하는데, 특정 관계형 데이터베이스 벤더에 구속되고 복잡해져  
  유지보수가 어려워지고 성능 문제가 발생했을 때 SQL 구문 튜닝이나 저장소 증설(Scale up)에 의존할 수밖에 없다.

- 또한 이러한 구조의 애플리케이션은 아무리 여러 개의 마이크로서비스로 분리하더라도 요청이 증가할 경우,  
  서비스는 한가하고 여러 서비스에서 호출되는 통합 데이터베이스만 여전히 바쁜 상황이 되어 마이크로서비스의 Scale Out 기능이  
  별 소용이 없어질 수 있다.

- 이를 보완할 수 있는 마이크로서비스 패턴인 저장소 분리 패턴은 각 마이크로서비스가 각자의 비즈니스 처리를 위한 데이터를  
  **직접 소유** 해야한다는 것을 말한다. 그렇기에 각 마이크로서비스가 소유한 데이터는 다른 서비스에 직접 노출하지 않고  
  각자가 공개한 API를 통해서만 접근할 수 있다(정보 은닉). 또한 저장소가 격리되어 있기에 각 저장소를 자율적으로 선택할 수도 있다.  
  궁극적으로 이 같은 제약이 데이터를 통한 변경의 파급 효과를 줄여 서비스를 독립적으로 만든다.

- 그러나 이처럼 마이크로서비스별로 기능을 분리하고 저장소를 격리함에 따라 이전에는 쉽게 해결했던 문제가 생긴다.  
 바로 여러 개의 분산된 서비스에 걸쳐 비즈니스 처리를 수행해야 하는 경우, 비즈니스 정합성 및 데이터 일관성을  
 어떻게 보장할 것인가에 대한 문제이다.
<hr/>

<h3>분산 트랜잭션 처리 패턴</h3>

- 손쉽게 처리할 수 있는 한 가지 방법은 여러 개의 분산된 서비스를 하나의 트랜잭션으로 묶는 것일 거다.  
  분산 트랜잭션 처리에는 여러 서비스 간의 비즈니스 및 데이터 일관성을 유지할 필요가 있다.  
  분산 트랜잭션 처리를 위한 전통적인 방법으로는 **2단계 커밋** 과 같은 방법이 있다.  
  2단계 커밋은 분산 데이터베이스 환경에서 원자성(atomicity)을 보장하기 위해 분산 트랜잭션에 포함되어 있는  
  모든 노드가 커밋되거나 롤백하는 메커니즘이다.

- 하지만 이 방법은 각 서비스이 잠금(Lock in)이 걸려 발생하는 성능 문제 탓에 효율적이지 못하다.  
  특히 각 서비스가 다른 인스턴스로 로딩되기에 통제하기가 어렵다. 또한 서비스의 저장소가 각각 다를 경우에 문제가 있으며,  
  특히 MongoDB와 같은 NoSQL 저장소는 2단계 커밋 자체를 지원하지 않는다.

- 특히 클라우드의 가장 큰 장애는 네트워크 장애인 경우가 많은데, 네트워크 장애 등으로 특정 서비스의 트랜잭션이  
  처리되지 않을 경우 트랜잭션이 묶인 서비스가 즉시 영향을 받기도 한다.

- 2단계 커밋을 통한 처리는 비자율적이고 독립적이지 못하다. 그 대신에 사용하는 방식은 바로 `Saga 패턴`이다.

- Saga Pattern은 각 서비스의 로컬 트랜잭션을 순차적으로 처리하는 패턴이다. Saga 패턴은 여러 개의 분산된  
  서비스를 하나의 트랜잭션으로 묶지 않고 각 `로컬 트랜잭션`과 `보상 트랜잭션`을 이용해 비즈니스 및 데이터의  
  정합성을 맞춘다. 각 로컬 트랜잭션은 자신의 데이터베이스를 업데이트한 다음, Saga 내에 있는 다음 로컬 트랜잭션을  
  trigger하는 메시지 또는 이벤트를 게시해서 데이터의 일관성을 맞춘다.

- 그렇다면 다른 트랜잭션의 결과에 따라 롤백이 필요한 경우는 어떻게 처리해야 할까?  
  여기서 나오는 개념이 `보상 트랜잭션`이다. 보상 트랜잭션은 어떤 서비스에서 트랜잭션 처리에 실패한 경우  
  그 서비스의 앞선 다른 서비스에서 처리된 트랜잭션을 롤백하게 하는 트랜잭션이다.

- 정리하자면, Saga Pattern은 일관성 유지가 필요한 트랜잭션을 모두 묶어 하나의 트랜잭션으로 처리하지 않고,  
  각 로컬 트랜잭션으로 분리해서 순차적으로 처리한다. 그러다가 도중에 트랜잭션이 실패한 경우 이전 로컬 트랜잭션이  
  작성한 변경 사항을 취소하는 일련의 보상 트랜잭션을 통해 비즈니스 처리의 일관성을 유지한다.

- 하나의 기능을 예로 들어보자. 주문 서비스와 고객 서비스가 있고, 주문을 처리할 때 고객의 신용한도 정보에 따라  
  최종 주문을 승인하는 기능이 있다. 이 두 서비스의 트랜잭션을 하나로 묶지 않고 보상 트랜잭션과 이벤트를 활용해  
  처리할 수 있다. 아래는 순서이다.

  - (1): 주문 처리가 시작되면 주문 서비스는 가주문을 생성하고, 주문자 정보가 담긴 _주문 생성됨_ 이벤트를  
     발행하고 트랜잭션을 종료한다.
  - (2): 고객 서비스가 _주문 생성됨_ 이라는 이벤트를 확인한 뒤, 다음 처리를 수행한다.
    - (2-a): 이벤트에 존재하는 주문자 정보로 고객의 신용한도를 조회해서 충족되면 _신용 승인됨_ 이벤트를 발행한다.
    - (2-b): 신용한도가 충족되지 않는다면 _신용한도 초과됨_ 이벤트를 발행한다.
  - (3): 주문 서비스는 고객 서비스가 발행한 이벤트를 확인해 다음 처리를 수행한다.
    - (3-a): 고객 서비스가 발행한 이벤트가 *신용 승인됨*인 경우에는 주문 승인 처리를 한다.
    - (3-b): _신용한도 초과됨_ 이벤트인 경우에는 보상 트랜잭션인 주문 처리 취소를 수행한다.

* 이처럼 하나의 큰 트랜잭션으로 묶지 않고 4개의 분리된 로컬 트랜잭션으로 비즈니스의 정합성을 맞출 수 있다.

<h4>데이터 일관성에 대한 생각의 전환: 결과적 일관성</h4>

- 모든 애플리케이션에는 비즈니스 처리를 위한 규칙이 있고, 이러한 비즈니스 규칙을 만족하도록  
  데이터의 일관성이 유지돼야 한다. 이전까지는 이 같은 데이터 일관성이 실시간으로 반드시 맞아야 한다는  
  생각이 일반적이었다. 그렇지만 과연 모든 비즈니스 규칙들이 실시간으로 일관성을 맞춰야 할까?

- 예를 들어, 쇼핑몰에서 주문을 하면 결제 처리가 돼야하고, 그 결제가 완료되면 결제 내용과 주문 처리 내역이  
  주문자에게 이메일로 발송되는 기능이 있다고 하자. 이 경우에 만약 미국의 Black Friday처럼 주문이 폭증한  
  경우를 생각해보자. 주문, 결제, 이메일 처리가 이렇게 순차적인 동시 일관성을 추구하는 경우에 만약 주문량이  
  폭증한다면 결제 처리가 되지 않거나 지연되는 경우가 발생할 수 있다. 그렇다면 결국 앞선 주문 처리도 지연될 것이다.  
  만약 이메일 발송도 외부 모듈을 사용한다면, 빠르게 요청 처리가 될 것이라는 보장을 할 수 없다.  
  따라서 이러한 상황을 고려했을 때 비즈니스 관점에서 보면 주문과 결제, 이메일 발송을 순차적으로 처리하기보다  
  무조건 **먼저 주문을 많이 받아 놓는 것** 이 좋을 수 있다.

- 이제 다시 생각해보자. 잘 생각해보면 비즈니스 처리가 반드시 실시간성을 요구하는 것은 아니다.  
  어떤 비즈니스는 데이터의 일관성이 실시간으로는 맞지 않더라도 어느 일정 시점이 됐을 때 일관성을 만족해도  
  되는 것이 있다. 이러한 개념을 결과적 일관성(Eventual Consistency)이라고 한다.

- 결과적 일관성의 개념은 고가용성을 극대화한다. 실시간성을 강조한다면 위의 예시처럼 하나의 서비스에서  
  장애가 발생하면 다른 서비스의 가용성 또한 떨어뜨릴 수 있다.

- 그럼 결과적 일관성의 개념으로 이 문제를 어떻게 해결할지 생각해보자.  
  이 비즈니스에 Saga Pattern과 Message 기반의 비동기 통신을 적용해보자.  
  각 마이크로서비스의 트랜잭션은 독립적이고 각 트랜잭션이 성공했을 때 상태 변경 이벤트를 발생해  
  이 이벤트를 구독한 다른 서비스의 로컬 트랜잭션이 작동되게 한다.

- 변경된 아키텍쳐의 실행 흐름을 보자.
  - (1): 가주문이 생성되고 _가주문됨_ 이벤트를 발행한다. 주문은 독립적인 로컬 트랜잭션이기 때문에  
    끊임없이 받을 수 있다. 주문이 몰릴 경우, 주문 서비스만 Scale-out하여 가용성을 높일 수 있다.
  - (2): _가주문됨_ 이벤트는 Message Broker에 의해 비동기로 전송된다.
  - (3): 결제 서비스는 발행된 _가주문됨_ 이벤트를 확인하고, 대금 결제 트랜잭션을 수행하고  
    _결제 처리됨_ 이벤트를 발행한다.
  - (4): 이메일 서비스는 _결제 처리됨_ 이벤트를 확인하고, 주문 결제 완료 이메일을 발송한다.
  - (5): 주문 서비스는 _결제 처리됨_ 이벤트를 확인하고 가주문으로 처리됐던 주문을 최종 승인한다.  
    그리고 _최종 주문 완료됨_ 이벤트를 발행한다.
  - (6): 이메일 서비스는 주문 서비스가 발행한 _최종 주문 완료됨_ 이벤트를 확인해 최종적으로 주문이  
    완료됐다는 이메일을 사용자에게 발송한다.
  - (7): 각 서비스는 각기 작업을 수행하다 오류가 발생하면 *실패 이벤트*를 발행해 다른 서비스가 비즈니스  
    정합성을 맞출 수 있게 한다.
  - (8): 이때 별도로 Message Queue에 쌓이는 이벤트들을 모니터링 서비스와 연계해 모니터링하고  
    추적해서 전체적인 비즈니스 정합성 여부를 관리자가 확인할 수도 있다.

* 이처럼 이벤트 기반 아키텍쳐와 Message Broker, Saga Pattern으로 비즈니스 정합성을 결과적으로  
  보장할 수 있고, 비즈니스 및 시스템 가용성을 극대화할 수 있다.

<hr/>

<h3>읽기와 쓰기 분리: CQRS Pattern</h3>

- 앞에서 Saga Pattern과 Event Message 기반의 비동기 통신을 활용해 가용성을 높인 것처럼,  
  비즈니스에 대한 기존 관념을 조금만 바꾸면 가용성을 높일 수 있는 방법이 다양하다.

- 마이크로서비스는 기본적으로 설계 철학에서 각 서비스별 데이터 저장소가 모두 다르다.  
  그런데 서비스의 성능 향상을 위해 서비스 인스턴스를 Scale out하게 되면, 데이터 읽기/수정 작업으로 인한  
  리소스 교착 상태가 발생할 수 있다.

- 이 문제를 해결하기 위한 방법으로 `CQRS Pattern`이 있는데, CQRS는 Command Query Responsibility  
  Segregation, 즉 **명령 조회 책임 분리** 를 의미한다. CQRS는 기존의 일반적이었던 동일한 저장소에 데이터를  
  넣고 CRUD를 모두 처리하는 방식에 도전하는 흥미로운 패러다임이다.

- 일반적으로 사용자의 비즈니스 요청은 크게 *시스템 상태를 변경하는 명령*과 *시스템의 상태를 조회하는 부분*으로 나뉜다.  
  그렇다면 실제 비즈니스 로직에서의 사용 빈도는 어떨까? 당연히 상태를 조회하는 부분이 많이 쓰인다.  
  즉, 일반적인 비즈니스 모델에서는 CRUD의 C,U,D가 R보다 적게 쓰이며, GET 요청이 훨씬 많이 사용된다.  
  그런데 서비스 내에 이러한 모든 기능을 넣어두면 조회 요청 빈도가 증가함에 따라 다른 명령 기능도 함께 확장해야 하므로  
  효율적이지 못하다.

- 하나의 저장소에 *쓰기 모델*과 *읽기 모델*을 분리하는 방식으로 변화시켜 쓰기 서비스와 조회 서비스를 분리할 수도 있고,  
  더 나아가 아예 물리적으로 쓰기 트랜잭션용 저장소와 조회용 저장소를 따로 준비할 수도 있다. 이렇게 쓰기 전략과  
  조회 전략을 각각 분리하면 쓰기 시스템의 부하를 줄이고 조회 대기 시간을 줄이는 등 엄청난 이점을 누릴 수 있다.

- 이러한 CQRS 방식을 이벤트 메시지 주도 아키텍쳐와 연계해서 예시를 통해 살펴보자.  
  우선 마이크로서비스는 명령 측면과 조회 측면의 두 부분으로 나뉜다.  
  명령 측면 마이크로서비스는 C,U,D 처리를 수행하고 저장소로는 Write에 최적화된 RDBMS를 사용한다.  
  그리고 프로그래밍 언어는 Java를 사용한다고 하자.  
  반면 조회 측면의 마이크로서비스는 조회 성능이 높은 MongoDB나 ElasticSearch와 같은 NoSQL 데이터베이스를  
  저장소로 사용하며, 프로그래밍 언어도 조회를 간단하게 구현할 수 있는 JavaScript(Node.js)를 사용한다.  
  조회 서비스는 사용량이 많기에 Scale out하여 인스턴스를 증가시켜 놓는다.

- 그런데 위와 같은 구조에서는 명령 서비스가 사용됨에 따라 조회 서비스와의 데이터 일관성이 깨지게 된다.  
  이때 데이터 일관성 유지를 위해 필요한 것이 이벤트 주도 아키텍쳐이다. 명령 서비스는 저장소에 데이터를 쓰면서  
  저장한 내역이 담긴 이벤트를 발생시켜 Message Broker에 전달하고, 조회 서비스는 Message Broker의  
  이벤트를 구독하고 있다가 이벤트 데이터를 가져와 데이터를 최신 상태로 동기화한다.  
  즉, 명령 서비스와 조회 서비스가 Message Broker로 연결되는 것이다.

- 물론 명령 서비스에 데이터가 들어간 즉시 조회 서비스의 데이터와 일치할 수 없고, 시간적 간격이 있을 수 있지만  
 어느 시점이 되면 결과적으로 일치하게 된다. 즉, 결과적 일관성을 추구하는 것이다.
<hr/>

<h3>API 조합과 CQRS</h3>

- CQRS 패턴은 다른 문제를 해결하기도 한다. 마이크로서비스의 저장소가 격리되어 있고 각 마이크로서비스마다  
  각기 다른 기능을 구현했을 때 여러 개의 마이크로서비스를 연계해서 서비스로 제공하는 경우에는 어떻개 해야 할까?

- 첫 번째 방법으로는 API Composition(API 조합)이 있다. *주문 이력 서비스*가 최종적으로 제공할  
  서비스라고 해보자. 이 서비스는 제품 서비스가 제공하는 제품 정보, 주문 서비스의 주문 정보, 고객 서비스의  
  특정 고객 정보, 배송 서비스의 배송 정보가 모두 다 필요하다. 따라서 각 기능을 제공하는 마이크로서비스를  
  조합하는 **상위 마이크로서비스** 를 만들어 조합된 기능을 제공할 수 있다. 하위 서비스는 각자 독립적인  
  API를 제공하면서 연계 API를 위해 상위 서비스에 정보를 제공한다.

- 그렇지만 이런 구조는 상위 서비스가 하위 서비스에 의존하는 결과를 가져온다. 상위 서비스가 제공하는 API에  
  정보를 제공하는 하위 서비스 중 하나라도 API를 변경하면 상위 서비스도 그에 따라 변경될 수밖에 없다.  
  또한 하위 서비스의 실패가 상위 서비스에 영향을 준다. 이러한 의존성을 줄이기 위한 방법이 필요하다.

- 두 번째 방법은 CQRS를 적용하는 것이다. 우선 *주문 이력 서비스*를 제공하는 마이크로서비스가 독자적인  
  저장소를 갖도록 만든다. 또한 주문 이력의 세세한 원천 정보를 보유하고 있는 배송, 주문, 제품 서비스도  
  독자적으로 자신들만의 저장소를 가지고 서비스를 제공한다. 그리고 이 원천 정보를 보유한 여러 마이크로서비스는  
  자신의 서비스의 정보가 변경되는 시점에 변경 내역을 각자의 변경 이벤트로 발행한다. 그럼 상위에 있는  
  *주문 이력 서비스*는 이 이벤트를 구독하고 있다가 이벤트를 가져와서 자신의 서비스의 저장소에  
  기록함으로써 다른 서비스의 데이터와 데이터 일관성을 맞추고 서비스의 주문 이력 조회 기능으로 제공한다.

- 위와 같은 경우에는 다른 원천 서비스가 순간적인 장애가 생긴다고 하더라도 주문 이력 서비스가 영향을  
  받지 않는다. 즉, 조회용 마이크로서비스를 별도로 생성하고 다른 서비스로부터 비동기 이벤트로  
  일관성을 맞춤으로써 API 조합 방식의 단점인 직접적인 의존성을 줄일 수 있는 것이다.

<hr/>

<h3>쓰기 최적화: 이벤트 소싱 패턴</h3>

- 지금까지 살펴본 Saga Pattern, CQRS Pattern에서 비즈니스의 불일치를 피하기 위해서는 저장소에 저장하는 것과  
  메시지를 보내는 것이 더 이상 쪼개질 수 없는 *원자성*을 지녀야 한다. 즉, 저장소에 저장하는 일과 메시지를 보내는  
  작업이 언제나 완전하게 진행되어 함께 실행되어야 한다는 것이다.

- 하지만 객체의 상태 변화를 이벤트 메시지로 발행하고, 또 객체 상태를 RDBMS에 저장하는 경우, SQL문으로 변환해서  
  처리하기가 매우 번거롭고 또 까다롭다. 또 메시지 발행과 저장 처리라는 2개의 기능을 수행하기에 빠르지도 않다.

- 그렇다면 이러한 메시지 발행 및 저장 처리의 원자성을 보장하고, 성능까지 챙겨갈 수 있는 방법은 무엇일까?  
  보통 비즈니스 처리를 수행할 때 데이터 처리는 항상 처리 상태의 결과값을 계산하고, 데이터의 최종 상태를  
  확정해서 저장하는 방식으로 진행된다. 예를 들어, 쇼핑몰의 장바구니에 품목을 추가, 삭제하는 과정을 보자.  
  만약 일반적인 RDBMS와 Java를 사용한다면, 장바구니, 품목 데이터 모델이 정의돼 있어야 하고 장바구니 상태를  
  변경할 때 매번 트랜잭션의 결과를 반영해서 장바구니 데이터 모델의 결과를 계산해야 한다.  
  객체의 상태 변화와 데이터 모델의 결과 변화 양상은 아래와 같다.

  - (1) 사용자 A의 장바구니 객체 생성 -> 장바구니 테이블에 A의 장바구니 row 삽입
  - (2) 품목 1 객체 추가 -> 품목 테이블에 사용자 A 장바구니의 품목 1 추가
  - (3) 품목 2 객체 추가 -> 품목 테이블에 사용자 A 장바구니의 품목 2 추가
  - (4) 품목 1 객체 제거 -> 품목 테이블에 사용자 A 장바구니의 품목 1 삭제
  - (5) 품목 2 객체의 수량 변경 -> 품목 테이블에 사용자 A 장바구니의 품목 2의 수량 정보 수정

- 위처럼 객체의 상태 변경에 따라 데이터 모델로 처리되고 최종값이 반영돼야 한다.  
  따라서 이 같은 과정은 복잡해지고 변환 처리가 느릴 수 밖에 없다. 특히 인스턴스가 여러 개로 확장될 때  
  동시 업데이트 및 교착 상태로부터 안전하지 못할 수도 있다.

- 그럼 객체 상태를 데이터 모델에 맞춰 계산하지 않고, 상태 트랜잭션 자체를 저장하면 어떨까?  
  이를 Event Sourcing(이벤트 소싱)기법이라 하는데, 트랜잭션 자체를 저장하는 전략이다.  
  즉, 상태 변경 이벤트를 계산해서 데이터 모델로 변경하지 않고 바로 이벤트 저장소에 그대로 저장한다.

- 이렇게 하면 Message Broker와 데이터 저장소를 분리하지 않고 하나로 사용할 수 있다. 복잡한 과정이 없으니  
  쓰기 속도가 훨씬 빠르다. 그럼 현재 시점의 상태가 필요할 때는 어떻게 해야 할까?  
  상태가 필요하면 상태의 출발점부터 모든 기록된 상태 변경 트랜잭션을 순차적으로 계산한다.

- 처음부터 모든 트랜잭션을 처리하는 것이 부담된다면 매일 자정에 상태를 계산한 후 Snapshot으로 저장한 후  
  현재 상태 정보가 필요해지면 Snapshot 이후의 트랜잭션만 처리하면 된다. 이러한 방식은 특정 시점의  
  상태가 필요하면 재현할 수도 있기에 별도의 트랜잭션성 이력 로그 데이터를 기록할 필요도 없다.

- 또 한가지 중요한 점은 명령 측면과 조회 측면의 서비스가 이벤트 저장소에 대한 CRUD를 모두 처리할 필요 없이  
  C,R만 처리하면 된다는 것이다. 저장소에서 U, D가 발생하지 않기에 명령 측면의 서비스를 여러 개 확장해도  
  동시 업데이트 및 교착상태가 발생하지 않는다.

- 이벤트 저장소의 형태 예시를 보자. Event ID가 있고, Event Type으로 어떤 상태인지, Entity Type으로  
  어떠한 객체의 이벤트인지, 그리고 변경 내용이 Entity Data에 JSON형태로 저장된 예시가 있다.

- 이 패턴에서의 이벤트는 한번 발생된 후에 update, delete 없이 insert만 되는 개념이라 동시성이나  
  정합성 등의 문제에 비교적 자유롭다.

- 정리하자면 이벤트 소싱은 모든 트랜잭션의 상태를 바로바로 계산하지 않고, 별도의 Event Stream 저장소에  
  저장하는 방식이다. 이벤트 스트림 저장소는 오로지 *추가*만 가능하게끔 해서 계속 이벤트들이 쌓이게 만들고,  
  실제로 내가 필요한 데이터를 구체화하는 시점에서는 그때까지 축적된 트랜잭션들을 바탕으로 상태를 계산해서  
  구성한다.

- 이벤트 저장소는 이벤트 데이터베이스의 역할뿐 아니라 Message Broker처럼 작동한다. 이는 데이터 저장 처리  
  메커니즘과 Message Queue와 같은 이벤트를 전달하기 위한 메커니즘을 통합해서 복잡성을 줄이고  
  특히 쓰기 성능을 최적화한다. 또한 상태를 저장하기 때문에 정확한 감사 로깅을 제공하며 객체의 예전 상태를  
  재구성하는 것이 단해지며, 외부 애플리케이션에 이벤트를 전달하는 것도 저장한 이벤트를 그대로 전송하면 되기에 간편하다.

- 이벤트 소싱 및 CQRS를 지원하는 프레임워크로 Java 진영에서는 Axon Framework와 Eventuate가 주로 사용된다.
<hr/>
