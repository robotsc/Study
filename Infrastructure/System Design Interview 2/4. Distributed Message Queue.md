# Distributed Message Queue

- 이번 장에서는 시스템 디자인 면접에서 자주 등장하는 질문인 분산 message queue를 설계해보자. 현대 아키텍쳐에서 시스템은 작고 서로 독립된  
  컴포넌트들로 나눠지고, 이들은 잘 정의된 인터페이스를 두고 소통한다. Message queue는 이 컴포넌트들이 서로 상호작용하는 방법을 제공한다.  
  그렇다면 message queue가 어떤 이점을 가져다 줄까?

  - Decoupling: Message queue는 서로 다른 컴포넌트가 강결합되는 것을 막아 서로 독립적으로 개발될 수 있게 한다.
  - Improved scalability: 트래픽량에 따라 producer와 consumer 각각을 확장할 수 있다. 예를 들어 사용량이 많은 시간대에는 consumer만  
    확장해 늘어난 트래픽을 처리하도록 할 수 있다.
  - Increased availability: 시스템의 일부가 장애가 난다면, 다른 컴포넌트들은 queue를 사용해 계속해 상호작용할 수 있다.
  - Better performance: Message queue는 비동기 통신을 쉽게 하도록 한다. Producer들은 queue에 consumer가 메시지를 소비하기를 기다리지  
    않고, 단순히 메시지를 전달하고 다른 일을 할 수 있다. 즉 consumer, producer가 서로의 작업이 완료되기를 기다릴 필요가 없다.

- 다음은 유명한 분산 message queue들이다.
  - Apache Kafka, Apache RocketMQ, RabbitMQ, Apache Pulsar, Apache ActiveMQ, ZeroMQ

#### Message queues vs Event streaming platforms

- 위의 유명한 message queue들 중 따지고 보면 Apache Kafka와 Pulsar는 event streaming platform이지, message queue는 아니다.  
  하지만 message queue와 event streaming platform을 구분짓는 경계를 허무는 다양한 기능들을 제공한다. 예를 들어 일반적인 message queue인  
  RabbitMQ는 선택적으로 stream 기능을 사용할 수 있도록 한다. 이 stream 기능은 event streaming platform처럼 append-only log 방식으로  
  구현되어 있고, 메시지의 반복적인 소비와 메시지의 생명주기를 길게 다룰 수 있도록 해준다. 또한 Apache Plusar는 Kafka의 대조군인데,  
  일반 분산 message queue로 사용해도 될 정도로 유연하고 성능이 좋다.

- 이번 장에서는 long data retention, repeated consumption of messages 등 event streaming platform에서 제공할 만한 추가적인  
  기능을 가진 분산 message queue를 설계해볼 것이다. 이 기능들은 설계를 더욱 복잡하게 한다.

## 문제 이해 및 설계 범위 확정

- 기본적으로 message queue의 기능은 매우 간결하고 단순한데, producer는 메시지를 queue에 보낼 수 있어야 하고, consumer들은 이 메시지들을  
  가져와 사용(소비)할 수 있어야 한다. 이 기능 외에도 성능, 메시지 전달 방식, 메시지 retention 등의 고려 요소들이 많다.  
  이번에 디자인할 분산 message queue가 제공하는 기능 요구사항은 아래와 같다.

  - Producer들은 메시지를 message queue에 보낼 수 있다.
  - Consumer들은 message queue로부터 메시지를 소비한다.
  - 메시지는 한 번, 또는 여러 번 소비될 수 있다.
  - 메시지의 크기는 KB 단위이다.
  - Queue에 메시지가 전달된 순서대로 consumer에게 전달된다.
  - 데이터 전달 방식(at-least once, at-most once, exactly once)는 사용자들이 설정할 수 있다.

- 아래는 비 기능적 요구사항들이다.

  - Use case에 따라 높은 처리량 또는 낮은 latency를 제공해야 한다.
  - Scalability: 시스템은 분산 처리되어 있어야 한다. 따라서 전송되는 메시지가 갑자기 치솟아도 이를 감당할 수 있어야 한다.
  - Persist, durable: 데이터는 disk에 저장되어야 하고, 여러 개의 node들에 복제되어야 한다.

### 일반적인 message queue

- 위 요구사항들은 일반적인 message queue에서는 제공하지 않는 기능들을 포함한다. 예를 들어 일반적인 message queue는 메시지를 소비될 때까지  
  메모리에만 보관하고, 일반적으로 메시지의 순서를 보장하지 않는다. 이 기능이 없으면 설계가 훨씬 쉬워진다.

---

## 개략적 설계안 제시 및 동의 구하기

- 첫 번째로 message queue의 기본적인 요구사항을 다뤄보자.

- 아래 그림은 message queue의 중요한 컴포넌트들과 이들간의 상호작용을 나타낸다.

  ![picture 48](/images/SDI2_MQ_1.png)

  - Producer는 message queue에 메시지를 보낸다.
  - Consumer는 queue를 구독하고, 해당 queue의 메시지를 소비한다.
  - Message queue는 producer와 consumer의 가운데에 위치해 이들을 decouple함으로써 각각 독립적으로 운영 및 확장할 수 있도록 한다.
  - Producer와 consumer 모두는 client/server model에서 client에 해당하고, message queue가 server에 해당한다.  
    Client, server는 네트워크를 통해 상호작용한다.

### Messaging Models

- 가장 유명한 messaging model은 point-to-point와 publish/subscribe 이다.

#### Point-to-point

- 이 모델은 전통적인 message queue에서 많이 사용된다. Point-to-point model에서는 메시지가 queue에 보내지고, 단 하나의 consumer에 의해  
  소비된다. 물론 queue로부터 메시지를 소비하기 위해 많은 consumer들이 있을 수 있지만, 각 메시지는 오직 단 하나의 consumer에 의해 소비된다.  
  아래 그림에서 메시지 A는 consumer 1에 의해 소비된다.

![picture 49](/images/SDI2_MQ_2.png)

- Consumer가 메시지를 소비하면 해당 메시지는 queue에서 제거된다. 즉 point-to-point model에서는 data retention이 없다.  
  이와 반대로 우리가 이번에 설계할 message queue는 메시지를 2주 동안 보관하기 위한 persistence layer가 있고, 이를 통해 메시지가 반복적으로 소비되게 한다.

#### Publish-subscribe

- 이 모델을 알기 전에 우선 topic이 무엇인지 보자. Topic은 메시지를 분류하기 위한 카테고리이다. 각 topic은 모든 message queue service에서  
  unique한 이름을 가진다. 그리고 메시지는 특정 topic을 갖고 message queue에 보내지고, 읽어진다.

- Publish-subscribe model에서 메시지는 topic으로 보내지고, 해당 topic을 구독하고 있는 consumer들에 의해 소비된다.  
  아래 그림에 나타난 것처럼, message A는 consumer1, consumer2 모두에 의해 소비된다.

  ![picture 50](/images/SDI2_MQ_3.png)

- 우리가 설계할 message queue는 위의 두 모델 모두를 지원한다. Publish-subscribe model은 **topic** 을 사용해 구현되고, point-to-point  
  model은 **consumer group** 을 사용해 구현된다.

### Topics, partitions, and brokers

- 이전에 봤듯이 메시지들은 topic으로 분류되고 저장된다. 그렇다면 단 하나의 서버가 처리하기에 topic의 데이터량이 너무 많으면 어떻게 될까?

- 이 문제를 해결하기 위한 하나의 접근법으로 **partition(sharding)** 을 사용할 수 있다. 아래 그림에 나타난 것처럼 topic을 partition들로  
  나누고, 각 partition에 고르게 메시지들을 전달한다. 여기서 partition을 _topic에 해당하는 메시지의 부분집합_ 으로 생각해도 된다.  
  Partition들은 message queue cluster 내의 서버들에 고르게 분포된다. 그리고 partition들을 갖는 서버를 **broker** 라 한다.  
  Broker들로 partition을 분배하는 것은 높은 확장성을 지원하기 위해 중요한 요소다. 특정 topic의 처리량을 partition의 개수를 늘림으로써  
  처리할 수 있다.

  ![picture 51](/images/SDI2_MQ_4.png)

- Topic의 각 partition은 queue와 함께 FIFO mechanism으로 운영된다. 즉 partition 내에 메시지의 순서를 그대로 보관한다는 뜻이다.  
  그리고 partition 내에 있는 메시지의 위치를 **offset** 이라 한다.

- 메시지가 producer에 의해 전달되면, 실제로는 해당 메시지의 topic의 partition들 중 하나로 전달된다. 각 메시지는 선택적으로 message key를  
  가지며, 같은 message key를 가진 메시지들은 모두 동일한 partition으로 전달된다. 만약 message key가 없다면 메시지는 partition들 중  
  하나로 랜덤으로 전달된다.

- Consumer가 topic에 구독하게 되면, 해당 topic의 하나 이상의 partition들로부터 데이터를 pull하게 된다. 특정 topic에 구독하는  
  consumer들이 여러 개 있다면, 각 consumer는 topic의 partition의 일부를 처리하는 책임이 부여된다. 이러한 consumer들은 topic에 대해 하나의  
  **consumer group** 을 형성하게 된다.

- Broker와 partition들로 구성된 Message queue cluster는 아래와 같이 구성되어 있다.

  ![picture 52](/images/SDI2_MQ_5.png)

### Consumer group

- 이전에 언급했듯이 우리가 설계하려는 message queue는 point-to-point와 publish-subscribe model 모두를 지원해야 한다.

- **Consumer group** 은 consumer들의 집합으로, 이 consumer group 내의 consumer들은 특정 topic의 메시지들을 소비하기 위해 협업한다.

- Consumer들은 group들로 구성될 수 있다. 각 consumer group은 여러 개의 topic을 구독할 수 있고, 각자 자신만의 소비 offset을 유지한다.  
  예를 들어 consumer들을 하나는 billing, 다른 하나는 accounting 처럼 use case별로 grouping할 수 있다.

- 동일한 consumer group 내의 consumer들은 트래픽을 병렬적으로 처리할 수 있다. 아래 그림을 보자.

  ![picture 53](/images/SDI2_MQ_6.png)

  - Consumer group 1은 topic A를 구독한다.
  - Consumer group 2는 topic A와 topic B를 구독한다.
  - Topic A는 consumer group 1과 consumer group 2 모두에 의해 구독되고 있다. 즉 동일한 메시지가 여러 개의 consumer들에 의해 소비될 수  
    있다. 이 패턴이 publish-subscribe model을 지원하도록 한다.

- 하지만 위 그림대로 진행하면 문제점이 하나 생긴다. 병렬적으로 데이터를 처리하는 것은 처리량을 높여주지만, 같은 partition내의 메시지가 소비되는 순서가  
  메시지가 전달된 순서와 같다는 것이 보장되지 못한다. 예를 들어 만약 consumer 1과 consumer 2가 모두 partition 1의 메시지를 소비해가면,  
  partition-1의 메시지 소비 순서를 보장하지 못하게 될 것이다.

- 이 문제는 하나의 partition은 같은 group에 속한 단 하나의 consumer에 의해 소비되어야 한다는 규칙을 추가함으로써 해결할 수 있다.  
  만약 consumer group내의 consumer의 개수가 partition의 개수보다 크다면, 일부 consumer는 아무런 데이터를 소비하지 못하게 될 것이다.  
  예를 들어 위 그림에서 consumer group 2에 속한 consumer 3는 이미 같은 consumer group에 속한 consumer 4가 topic B를 구독하고  
  있으므로 topic B로부터 메시지를 소비하지 못한다.

- 이 규칙을 적용해 만약 하나의 consumer group에 모든 consumer들을 배치하게 된다면 동일한 partition에 있는 메시지들을 각각 단 하나의  
  consumer에 의해 소비될 것이고, 이는 곧 point-to-point model과 같다. Partition이 가장 작은 storage unit이니 사전에 미리 충분한  
  수의 partition들을 배치해놔 동적으로 partition의 개수를 늘리지 않도록 하면 좋다. 확장이 필요하다면 오로지 consumer만 추가하면 된다.

### 개략적 설계안

- 아래 그림은 위에서 다룬 모든 내용을 포함한 개략적 설계안이다.

  ![picture 54](/images/SDI2_MQ_7.png)

  - Clients

    - Producer: 메시지를 특정 topic으로 push한다.
    - Consumer group: Topic을 구독하며 메시지를 소비한다.

  - Core service and storage

    - Broker: 여러 개의 partition을 가진다. Partition은 특정 topic 내의 메시지들의 부분 집합을 가진다.
    - Storage:
      - Data storage: 메시지는 partition 내의 data storage에 보관된다.
      - State storage: Consumer의 상태를 보관한다.
      - Metadata storage: 설정 값 및 topic의 속성들을 보관한다.

  - Coordination service:

    - Service discovery: 어떤 broker들이 사용 가능한지를 알려준다.
    - Leader election: Broker들 중 하나가 active controller로 선택된다. Cluser 내에는 단 하나의 active controller 만이 존재한다.  
      Active controller는 partition을 할당하는 작업에 대한 책임을 가진다.
    - 주로 controller를 선정하기 위해 Apache ZooKeeper, etcd 등이 사용된다.

---
