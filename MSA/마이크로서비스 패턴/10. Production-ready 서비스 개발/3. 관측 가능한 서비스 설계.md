# 관측 가능한 서비스 설계

- 서비스를 production에 배포하면 초당 요청 수, 리소스 이용률 등 현재 애플리케이션의 상태를 추적해야 한다.  
  서비스 인스턴스가 실패하거나 디스크가 다 차버리는 등의 문제가 생기면 사용자에게 영향을 끼치기 전에 그 사실을  
  알아내고 대응해야 하기 때문이다.

- 하드웨어의 가용성, 이용률을 모니터링하는 등 애플리케이션을 운영하는 일은 대부분 운영자의 몫이지만, 개발자가 서비스 인스턴스의  
  동작과 health가 표출되도록 개발하면 운영자가 좀 더 쉽게 관리하고 troubleshooting할 수 있을 것이다.

- 아래는 이러한 관측 가능한 서비스를 설계하는 패턴이다.

  - **Health check API** : 서비스의 health를 반환하는 endpoint를 표출한다.
  - **Log aggregation** : 서비스 활동을 logging하면서 검색/경고 기능이 구현된 중앙 로그 서버에 로그를 출력한다.
  - **Distributed tracing** : 각 외부 요청에 ID를 하나씩 부여해 서비스 사이를 드나드는 과정을 추적한다.
  - **Exception tracking** : 예외 중복 제거, 개발자 알림, 예외별 해결 상황 추적 등을 수행하는 예외 추적 서비스에 예외를 보고한다.
  - **Application metrics** : 카운터, 게이지 등의 지표를 유지하고 수집한 데이터를 지표 서버에 표출한다.
  - **Audit logging** : 사용자 액션을 logging한다.

  ![picture 110](/images/MSAP_PRDS_10.png)

- 이런 패턴들의 가장 두드러진 특징은 개발자, 운영자 각자의 업무 영역이 각각 정해져 있다는 것이다.  
  가령 health check API 패턴에서 개발자는 본인이 개발한 서비스의 health check endpoint를 정확히 구현하고, 운영자는  
  health check API를 주기적으로 호출해 시스템을 모니터링한다. Log aggregation도 개발자는 서비스가 유용한 로그를 남기도록  
  개발하고, 운영자는 로그를 수집한다.

## Health check API 패턴

- 실행 중이지만 요청을 처리할 수 없는 서비스가 있다. 예를 들어 이제 막 시작한 서비스 인스턴스도 준비가 다 끝날 때까지 요청을 받아  
  처리할 수 없다. 요청을 처리할 준비가 덜 된 상황에서 배포 인프라가 서비스 인스턴스에 HTTP 요청을 routing해봐야 무의미할 것이다.

- 또한 서비스 인스턴스가 중단되지 않고 실패할 수도 있다. 예를 들어 DB connection이 고갈되어 DB에 접근할 수 없을 수 있다.  
  실행 중이지만 실패한 서비스 인스턴스에는 요청을 보내면 안된다. 서비스 인스턴스가 복원되지 않으면 강제로 종료시킨 후 새로운  
  인스턴스를 생성해야 한다.

> Health check API: 서비스가 자신의 상태를 반환하는 `GET /health` 등의 health check API endpoint를 표출한다.

- 서비스 인스턴스는 자신이 요청을 처리할 수 있는 상태인지의 여부를 배포 인프라에 알려야 한다. 배포 인프라가 호출할 수 있는 health check  
  endpoint를 서비스에 구현하는 것이 좋은 방법이다. 배포 인프라는 서비스 인스턴스의 health 상태를 계속해 살피고, 문제가 있으면 즉시 조치를  
  할 수 있도록 주기적으로 health check endpoint를 호출한다.

  ![picture 111](/images/MSAP_PRDS_11.png)

- Health check 요청 핸들러는 서비스 인스턴스 및 외부 서비스의 접속 상태를 확인한다. DB에도 주기적으로 test query를 전송한다.  
  이 핸들러는 비어있는 HTTP respons에 적절한 status code를 반환할 때도 있지만, 각 adapter의 자세한 health 정보도 반환한다.  
  이 정보는 troubleshooting할 때 도움이 된다. 그러나 민감한 정보도 포함될 수 있기에 구현에 주의가 필요하다.

- Health check 기능을 구현할 때에는 서비스 인스턴스의 health를 보고하는 endpoint를 어떻게 구현할지, 배포 인프라는 helath check  
  endpoint를 어떻게 호출할지의 2개를 고려해야 한다.

### Health check endpoint 구현

- Health check endpoint를 구현한 코드는 서비스 인스턴스의 상태를 어떻게든 판단해야 한다. 일단 서비스 인스턴스가 외부 인프라 서비스에  
  접근 가능한지 확인하면 될 것이다. 물론 방법은 인프라 서비스마다 다르다. 예를 들어 RDBMS의 접속 상태는 DB connection을 획득하고  
  test query를 실행하면 알 수 있다. 클라이언트의 서비스 API 호출을 mocking한 가짜 transaction을 실행하면 더 정교하고 철저하게  
  health check를 할 수 있지만, 이는 구현하는 데 시간이 걸리고 노력도 많이 든다.

### Health check endpoint 호출

- Health check endpoint를 호출하는 코드가 없으면 health check endpoint 자체가 무의미하기 때문에 서비스를 배포할 때 배포  
  인프라가 이를 호출하게 해야 한다. 방법은 세부 인프라 구조마다 다르다. 예를 들어 Netflix Eureka 같은 service registry가  
  health check endpoint를 호출하도록 구성해 네트워크 트래픽이 서비스 인스턴스로 전송되었는지 확인할 수 있다.

---

## Log aggregation 패턴

- 로그는 소중한 troubleshooting 도구이다. 애플리케이션의 문제가 무엇인지 확인하려면 로그 파일부터 봐야하기 때문이다.  
  하지만 MSA에서는 로그를 이용하는 것이 쉽지 않다. 예를 들어, 로그 파일이 API gateway와 여러 서비스에 흩어져 있는 상황에서  
  필요한 로그 항목을 어떻게 끌어모을 수 있을까?

- 정답은 log aggregation(로그 수집)이다. 모든 서비스 인스턴스가 남긴 로그를 log aggregation pipeline을 통해 중앙 logging  
  서버로 보내는 것이다. Logging 서버에 저장된 로그 데이터는 간편하게 조회, 검색, 분석할 수 있고 특정한 메시지가 로그에 있으면  
  알림을 전송하도록 구성할 수도 있다.

  ![picture 112](/images/MSAP_PRDS_12.png)

- Logging pipeline과 logging 서버는 보통 운영팀이 담당하지만, 유용한 로그를 남기도록 코딩하는 작업은 서비스 개발자의 몫이다.

### 서비스 로그 생성

- 서비스 개발자는 적합한 logging 라이브러리를 선택한 후, 로그 항목을 어디에 출력할지 정해야 한다.

- 프로그래밍 언어는 올바르게 구성된 로그 항목을 쉽게 생성할 수 있는 logging library를 하나쯤은 갖고 있다. Java에는 Logback,  
  Log4J, JUL, SLF4J 등이, Node.js에는 Log4Js 등이 있다. 이러한 라이브러리를 이용해 로그를 남기는 코드를 서비스 곳곳에  
  심어둬야 한다.

- 로그를 남길 장소도 결정해야 한다. 기존에는 잘 알려진 file system 경로에 로그 파일이 생성되도록 프레임워크를 설정했지만  
  container, serverless 등 요즘의 배포 기술에서는 보통 이렇게 하지 않는다. 가령 AWS Lambda는 로그를 출력할 _영구적인_  
  file system 자체가 없으므로 stdout에 logging해야 한다.

- 서비스의 로그 출력 결과를 갖고 뭘 할지는 배포 인프라가 결정한다.

### 로그 수집 인프라

- Logging 인프라는 로그를 수집, 저장한다. 사용자는 이렇게 저장된 로그를 검색할 수 있다.  
  대표적으로 사용되는 ELK stack은 아래의 3개 오픈 소스로 구성된 대표적인 logging 인프라이다.

  - Elasticsearch: Logging server로 쓰이는 텍스트 검색에 최적화된 NoSQL Database
  - Logstash: 서비스 로그를 수집해 Elasticsearch에 출력하는 log pipeline
  - Kibana: Elasticsearch 전용 시각화 도구

- 다른 오픈 소스 로그 pipeline으로는 Fluentd나 Apache Flume이 있고, logging 서버는 AWS CloudWatch Logs 등의 다양한 상용  
  제품들이 있다.

---

## Distributed tracing(분산 추적) 패턴

- 특정 query 요청이 느려진 원인을 찾아야 한다고 해보자. 외부 네트워크는 문제가 없고 API gateway, 서비스 중 한 곳에서 응답이 지연되었을  
  가능성이 높다. 서비스다마의 평균 응답 시간을 계산해보면 알겠지만 이는 전체 요청에 대한 평균 시간이지, 개별 요청을 하나하나 측정한 시간은  
  아니다. 게다가 서비스 호출이 많이 중첩되면 복잡해지고, 한 사람이 그 모든 서비스를 다 잘 알리도 없다.  
  이렇게 MSA에서는 성능 문제를 진단하고 troubleshooting하기가 어려울 수 있다.

> 분산 추적 패턴: 외부 요청마다 유일한 ID를 부여해 한 서비스에서 다음 서비스로 흘러가는 과정을 기록하고, 시각화/분석 기능을 제공하는  
> 중앙화 서버에 남긴다.

- 애플리케이션이 무슨 일을 하고 있는지 들여다보는 좋은 방법은 distributed tracing(분산 추적)을 활용하는 것이다. 분산 추적은 모놀리틱  
  애플리케이션의 performance profiler와 비슷한 것으로, 요청을 처리할 때마다 서비스 호출 tree 정보를 기록한다. 따라서 서비스가 외부  
  요청을 처리하며 어떤 상호작용을 했는지, 어느 지점에서 얼만큼의 시간을 썼는지 파악할 수 있다.

- 아래 그림은 분산 추적 서버가 API gateway가 요청을 처리할 때 일어났던 일을 화면에 나타낸 모습이다. API gateway로 들어온 inbound  
  request와 gateway가 다른 서비스에 요청한 내용이 담겨있다. 이렇게 분산 추적 서버는 각 요청마다 수행한 작업과 시간을 표시한다.

  ![picture 113](/images/MSAP_PRDS_13.png)

- 위와 같은 그림을 trace라 한다. 외부 요청을 나타내는 trace는 하나 이상의 span으로 구성된다.  
  Span은 작업을 나타내며 작업명, 시작/종료 timestamp가 주요 속성이다. 중첩된 작업은 하나 이상의 자식 span으로 나타내어진다.  
  위 그림에서 최상위 span은 API gateway 호출이고 자식 span은 API gateway의 서비스 호출이다.

- 분산 추적은 각 외부 요청마다 ID를 부여하는 부수 효과를 유발한다. 서비스는 이 요청 ID를 로그에 남길 수도 있고, 특정 외부 요청에 대한  
  로그 항목은 수집된 로그에서 이 ID로 쉽게 찾아낼 수 있다.

- 추적 정보 전파에 대한 표준으로 `X-B3-TraceId`, `X-B3-ParentSpanId`와 같은 header가 주로 사용된다.  
  분산 추적 서버는 trace들을 저장하고 UI로 시각화해 표시하는 기능을 제공한다.

  ![picture 114](/images/MSAP_PRDS_14.png)

---

## Application metrics(애플리케이션 지표) 패턴

- 운영 환경에서 monitoring과 alert 기능은 매우 중요하다. 모니터링 시스템은 대부분의 기술 스택에서 모든 부분의 지표를 수집해 중요한  
  애플리케이션의 health 정보를 제공한다. 수집하는 지표는 인프라 수준(ex. CPU, memory, disk usage)부터 애플리케이션 수준  
  (ex. 서비스 latency, 요청 수)까지 매우 다양하다. 이러한 지표는 시각화/알림 기능을 제공하는 지표 서비스가 수집한다.

> Application metrics 패턴: 서비스는 수집, 시각화, 알림 기능을 제공하는 중앙 서버로 지표를 보고한다.

![picture 115](/images/MSAP_PRDS_15.png)

- 지표는 주기적으로 sampling한다. 아래는 지표 sample의 세 가지 속성이다.

  - name: 지표명(ex. `jvm_memory_max_bytes`, `placed_orders`)
  - value: 수치 값
  - timestamp: sampling 시간

- 모니터링 역시 대부분 운영팀이 관장하지만 서비스 개발자도 2가지 임무가 있다. 첫째로 서비스가 자신의 동작에 관한 지표를 수집하도록  
  구성해야 한다. 둘째로 이러한 지표를 JVM 및 애플리케이션 프레임워크 수준에서 수집한 지표와 함께 지표 서버에 표출해야 한다.

### 지표 서비스에 지표 전달

- 서비스는 수집한 지표를 push 또는 pull 방식으로 metrics 서비스에 전달한다. Push model은 서비스 인스턴스가 API를 호출해  
  metrics 서비스에 지표를 push하는 방법이다.(ex. AWS CloudWatch)

- Pull model은 metrics 서비스 또는 로컬에서 실행되는 agent가 서비스 API를 호출해 서비스 인스턴스로부터 지표를 pull해오는  
  방법이다.(ex. Prometheus)

- 애플리케이션 metric은 애플리케이션의 동작을 파악할 수 있는 중요한 단서를 제공하며, 알림 기능을 사용하면 운영자가 장애가 발생했을 때  
  악영향의 범위가 더 커지기 전에 신속히 조치할 수 있다.

---

## 예외 추적 패턴

- 예외 로그를 남겨야 하는 경우는 드물지만, 예외는 문제의 근본 원인을 식별하는 데 중요한 단서이다. 또한 예외는 시스템 실패 또는 프로그래밍  
  버그의 징후이기도 하다. 기존에는 직접 로그 파일에서 예외를 검색하거나 로그 파일에 예외가 출현하면 알림을 보내도록 logging 서버를 구성했지만,  
  이런 방식은 아래의 한계들이 존재한다.

  - 로그 파일은 대부분 한 줄짜리 로그 항목이 많지만, 예외는 보통 여러 줄로 나온다.
  - 로그 파일에 있는 예외의 해결 과정을 추적할 메커니즘이 없다. 결국 예외를 issue tracker에 일일이 복사/붙여넣기해야 한다.
  - 중복된 예외를 자동으로 하나의 예외로 식별해 처리할 방법이 없다.

> 예외 추적 패턴: 서비스는 중복된 예외를 제거하고, 알림을 생성하고, 예외 해결 과정을 관리하는 중앙 서비스에 예외를 보고한다.

- 위의 한계들을 극복하기 위해 중복된 예외들을 제거하고, 알림을 생성하고, 예외 해결 과정을 관리하는 예외 추적 서비스를 따로 두는 것이 좋다.  
  예를 들어, 서비스에 예외가 발생하면 무조건 REST API 등을 사용해 예외 추적 서비스에 보고하도록 구성하는 것이다.

- 서비스가 예외 추적 서비스 API를 직접 호출해도 되지만, 예외 추적 서비스에 내장된 클라이언트 라이브러리를 활용할 수도 있다.

> 예외 추적 서비스는 순수 클라우드 기반의 HoneyBadger도 있고, 인프라에 쉽게 배포 가능한 Sentry도 있다.  
> 이런 서비스들은 애플리케이션 예외를 받아 알림을 생성하고, 예외 및 그 해결 과정을 조회/관리하는 console이 있다.  
> 예외 추적 서비스는 대부분 다양한 언어로 개발된 클라이언트 라이브러리들을 제공한다.

![picture 116](/images/MSAP_PRDS_16.png)

- 이러한 예외 추적 패턴은 운영 이슈를 신속하게 발견해 대응할 수 있게 해주는 유용한 수단이다.

---
