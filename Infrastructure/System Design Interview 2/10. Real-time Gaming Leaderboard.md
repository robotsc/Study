# Real-time Gaming Leaderboard

- 이번 장에서는 온라인 모바일 게임에서 사용되는 순위표를 설계해볼 것이다.

- 순위표란 무엇일까? 순위표는 토너먼트, 대결 등의 상황에서 사용자들의 순위를 나타낸다. 사용자들은 특정 작업이나 챌린지를 통과해  
  포인트를 획득할 수 있으며, 포인트가 많으면 많을수록 순위가 올라간다. 아래 그림은 모바일 게임에서 사용되는 순위표의 예시이다.

![picture 76](/images/SDI2_RGL_1.png)

## 문제 이해 및 설계 범위 확정

- 순위표는 상당히 직관적이지만 구현 할 때 복잡도를 증가시킬 수 있는 요소들이 많다. 따라서 다른 시스템 설계와 마찬가지로 우선  
  요구사항을 확실히 정의해야 한다.

### 기능적 요구사항

- 사용자는 토너먼트 동안 경기를 승리하면 포인트를 획득한다. 그리고 승리 시 마다 포인트가 누적된다.
- 모든 사용자는 순위표에 나타나야 한다.
- 순위표는 매달 초기화된다.
- 토너먼트 중 DAU는 500만명이며 MAU는 2500만명이다.
- 순위표는 기본적으로 top 10 사용자들 만을 표시한다.
- 토너먼트 중 한 사용자는 평균적으로 하루에 10개의 경기를 진행한다.
- 2명 이상의 사용자가 동일한 포인트를 가지고 있다면, 이들의 순위는 같은 순위로 취급된다.
- 순위표는 실시간으로 갱신되어야 한다.(near real-time도 허용)

### 비 기능적 요구사항

- 일반적인 확장성, 가용성, 안정성 요구사항들(높으면 높을 수록 좋다.)

### 추정치 계산

- 우리가 설계할 순위표의 규모를 파악하기 위해 몇 가지 수치들을 계산해보자.

- DAU가 500만명인 상황에서 사용자들이 균등한 분포로 경기를 진행한다고 했을 때 초당 `5,000,000 / 10^5 = 50`명이 경기를 진행한다.  
  하지만 실세계에서 이렇게 계산하는 경우는 적다. Peak hour가 존재하기도 하고, 시간대가 지역마다 다르기 때문에 사용량이 시간 마다 다르다.  
  이를 반영하기 위해 peak 시간대에는 평균보다 5배의 사용자가 있다고 해보자. 따라서 peak 시간대에는 초당 250명의 사용자들이 경기를 진행한다.

- 사용자가 평균적으로 하루에 10개의 경기를 진행하므로 사용자가 포인트를 획득하는 QPS는 `50 * 10 = 500`이다.  
  Peak QPS는 `250 * 5 = 2500`이다.

- 마지막으로 Top 10 사용자들을 순위표에서 조회하는 QPS를 계산해보자. 사용자가 게임에 하루에 한 번 접속한다고 가정했을 때 top 10 순위표는  
  사용자가 처음 게임에 접속했을 때 불러와진다. 따라서 QPS는 50 정도 될 것이다.

---

## 개략적 설계안 제시 및 동의 구하기

- 이번에는 API 설계, 개략적 설계안, 그리고 data model에 대해 다뤄보자.

### API 설계

- 개략적으로 봤을 때 아래의 3개 API들이 필요해 보인다.

- `POST /v1/scores`

  - 사용자가 게임에서 승리했을 때 순위표의 포지션을 갱신한다. 이 API는 game server들로부터만 호출될 수 있는 internal API여야 한다.  
    Request parameter는 아래 표와 같다.

    | field     | 설명                      |
    | :-------- | :------------------------ |
    | `user_id` | 게임에 승리한 사용자      |
    | `points`  | 게임에 승리해 얻은 포인트 |

  - 응답은 아래와 같다.

    | name            | 설명           |
    | :-------------- | :------------- |
    | 200 ok          | 정상 처리      |
    | 400 bad request | 요청 처리 실패 |

- `GET /v1/scores`

  - 순위표에서 top 10명의 사용자들을 조회한다. 응답 예시는 아래와 같다.
    ```json
    {
      "data": [
        {
          "user_id": "user_id1",
          "user_name": "alice",
          "rank": 1,
          "score": 976
        },
        {
          "user_id": "user_id2",
          "user_name": "bob",
          "rank": 2,
          "score": 943
        }
      ],
      ...
      "total": 10
    }
    ```

- `GET /v1/scores/{user_id}`

  - 특정 사용자의 rank를 조회한다. 응답 예시는 아래와 같다.

    ```json
    {
      "user_info": {
        "user_id": "user5",
        "score": 940,
        "rank": 6
      }
    }
    ```

### 개략적 설계안

- 이 시스템의 개략적 설계안은 아래 그림과 같다. 해당 설계에는 2개의 서비스가 존재한다. Game service는 사용자가 게임을 플레이하도록 하고  
  Leaderboard service는 순위표를 생성하고 보여준다.

  ![picture 77](/images/SDI2_RGL_2.png)

- 각 과정을 살펴보자.

  - (1) 사용자가 게임에서 승리하면 클라이언트는 game service로 요청을 보낸다.
  - (2) Game service는 게임에서 승리했다는 사실을 검증하고 Leaderboard service가 점수를 갱신하도록 호출한다.
  - (3) Leaderboard service는 Leaderboard store에 있는 사용자의 점수를 갱신한다.
  - (4) 사용자는 아래의 정보들을 포함해 Leaderboard service에 순위표 데이터 조회 요청을 보낸다.

    - Top 10 순위표
    - 해당 사용자의 순위

- 설계를 더 깊게 보기 전, 여러 가지의 선택지들을 두고 비교해보도록 하자.

#### 클라이언트가 Leaderboard Service로 직접 요청을 보내야 할까?

- 아래는 클라이언트가 Leaderboard Service를 호출하는 두 가지 방식을 보여준다.

  ![picture 78](/images/SDI2_RGL_3.png)

- 위의 두 가지 설계 중 Alternative Option에서 사용자의 포인트는 클라이언트가 직접 요청을 보냄으로써 갱신된다.  
  이 방식은 man-in-the-middle attack(중간자 공격)에 노출될 위험이 있어 안전하지 않다.

  > Man-in-the-middle attack: 사용자와 Leaderboard Service에 proxy를 두어 점수를 마음대로 갱신시킨다.

- 일반적으로 포커와 같은 server-authoritive(서버에서 모든 권한을 관리, 인가 하는) 게임들에서는 클라이언트가 점수를 설정하기 위해  
  game server를 호출할 필요가 없다. Game server는 게임 로직을 처리하기에 언제 게임이 끝나는지 알고 있으며, 끝나는 순간  
  Leaderboard service를 호출하면 되므로 클라이언트가 굳이 이 과정에 개입할 필요가 없다.

#### Game service, Leaderboard service 사이에 message queue를 둬야 할까?

- 위 질문에 대한 답은 게임 점수들이 어떻게 사용되는지에 따라 결정된다. 만약 데이터가 다양한 곳에서 사용되거나 여러 개의 기능을  
  구현하는 데에 사용된다면, 아래 그림처럼 Kafka를 이 두 서비스 사이에 두는 것이 적절하다.

  ![picture 79](/images/SDI2_RGL_4.png)

- 위 방식대로 하면 Kafka 내의 같은 데이터가 Leaderboard service, Analytic service, Push notification service 등  
  다수의 consumer들에 의해 소비될 수 있다. 게임이 두 사용자가 순서대로 플레이하거나 멀티 플레이어 게임이어서 다른 사용자들에게 점수가  
  갱신됨을 알려야 하는 경우에 유용할 것이다. 하지만 이 모든 사항은 설계 요구사항에 정의되어 있지 않으니, 우리가 이번에 설계할 시스템에서는  
  message queue를 사용하지 않도록 한다.

### Data models

- 설계한 시스템 중 핵심 컴포넌트 중 하나는 Leaderboard store이다. 이 컴포넌트에 어떤 데이터베이스를 사용할지 결정해보자.

#### RDBMS

- 우선 한 단계 물러나 가장 간단한 해결책을 생각해보자. 규모가 작은 경우에는 무엇이 좋을까?

- 규모가 작다면 대부분의 경우 RDBMS를 사용해 순위표를 단순하게 구현할 것이다. 매달 생성되는 순위표는 `user_id`, `score` column을  
  포함하는 데이터베이스 table로 표현될 수 있다. 사용자가 경기에서 승리하면 포인터를 누적시키고, 새로운 사용자라면 새로운 row를 추가하면  
  될 것이다. 그리고 사용자의 순위를 결정하기 위해 `score`를 DESC 순서대로 정렬하면 된다.

- `leaderboard` table은 아래와 같다.

  ![picture 80](/images/SDI2_RGL_5.png)

- 실 세계에서 `leaderboard` table은 `game_id`, `created_at` 등의 추가적인 정보를 담게될 것이다. 하지만 순위표를 어떻게 query하고  
  갱신할 것인지는 이들에 대해 고려하지 않아도 동일하다. 단순함을 위해 오직 현재 달의 순위표 데이터만 `leaderboard` table에 저장되어 있다 해보자.

- 사용자가 승리해 포인트를 획득하는 경우, 아래와 같이 처리된다.

  ![picture 81](/images/SDI2_RGL_6.png)

  - 포인트가 항상 1점씩 증가된다고 해보자. 만약 해당 사용자의 entry가 없다면, 아래처럼 새로운 row가 삽입될 것이다.

    ```sql
    INSERT INTO leaderboard (user_id, score) VALUES ('mary123', 1);
    ```

  - 이미 존재한다면 아래처럼 UPDATE를 수행할 것이다.

    ```sql
    UPDATE leaderboard SET score = score + 1 WHERE user_id = 'mary123';
    ```

- 특정 사용자의 순위를 찾는 과정은 아래와 같이 처리된다.

  ![picture 82](/images/SDI2_RGL_7.png)

  - 사용자의 순위를 가져오기 위해서는 아래의 query가 수행된다.

    ```sql
    SELECT (@rownum := @rownum + 1) AS rank, user_id, score
    FROM leaderboard
    ORDER BY score DESC;
    ```

  - 그리고 위 query의 수행 결과는 아래와 같을 것이다.

    | rank | `user_id`    | score |
    | ---- | ------------ | ----- |
    | 1    | happy_tomato | 987   |
    | 2    | mallow       | 902   |
    | 3    | smith        | 870   |
    | 4    | mary123      | 850   |

- 이렇게 RDBMS를 사용한 방법은 데이터량이 적을 때는 동작하지만 수백만개의 row가 생기면 query 수행 시간이 느려진다.  
  왜 느려지는지 간단히 살펴보자.

  - 특정 사용자의 정확한 현재 순위를 알아내기 위해 모든 row를 포인트를 기준으로 정렬해야 한다.  
    요구사항에서는 포인트가 동일한 사용자는 같은 순위를 가지도록 처리되어야 한다고 했다. 따라서 정렬된 결과 자체를 순위로 사용할 수 없다.

  - SQL 데이터베이스는 지속적으로 변경되는 대량의 정보를 처리하기에 성능이 좋지 못하다. 수백만 개 이상의 row를 가진 table에 대해 정렬을  
    수행하면 10초대의 시간이 소요되며, 이는 요구사항이 말하는 near real-time에도 근접하지 못한다. 데이터가 지속적으로 변경되기 때문에  
    cache를 적용하기도 꽤나 까다롭다.

  - RDBMS는 대량의 read query를 적절히 처리하도록 설계되어 있지 않다. RDBMS는 batch 작업으로 이를 수행하면 성공적으로 처리할 수  
    있지만, batch를 수행하는 것은 요구사항의 near real-time 요건을 만족시키지 못한다.

- 위의 문제들을 최적화하는 방법으로 index를 추가하고 LIMIT 절을 사용해 scan할 페이지를 제한할 수 있다. Query는 아래와 같다.

  ```sql
  SELECT (@rownum := @rownum + 1) AS rank, user_id, score
  FROM leaderboard
  ORDER BY score DESC
  LIMIT 10;
  ```

- 하지만 위 최적화 방법은 확장성이 떨어진다. 우선 사용자의 순위를 찾는 것 자체는 table scan을 동반하므로 성능이 좋지 않다.  
  둘째로 이 해결책은 순위표의 top 10에 들지 않는 사용자들의 순위를 효율적으로 결정하는 뾰족한 방법을 제공하지 않는다.

#### Redis

- 우리는 수백만 명의 사용자가 있어도 어느 정도의 성능을 보장할 수 있고 순위표 관련 연산을 쉽게 지원하는 데이터베이스를 사용해야 한다.  
  이에 Redis를 사용할 수 있는데, Redis는 key-value pair들을 지원하는 in-memory data store이다. Memory에서 동작하기에  
  빠른 read, write가 가능하다. 또한 Redis는 순위표 설계에 적절한 **sorted set** 이라는 데이터 타입을 제공한다.

- 그렇다면 Redis sorted set은 무엇일까?  
  Sorted set은 set과 비슷한 데이터 타입으로, 우리가 설계하는 시스템으로 가정하면 sorted set 내의 각 사용자는 자신의 포인트와  
  연관되게 된다. Sorted set 내의 사용자 각각은 unique해야 하지만, 포인트 값은 중복될 수 있다. 그리고 포인트 값을 사용해  
  sorted set 내의 데이터를 정렬할 수 있다.

- 따라서 우리가 설계하는 순위표는 sorted set과 정말 잘 들어맞는다. 내부적으로 sorted set은 hash table과 skip list로  
  구현되어 있다. Hash table은 사용자를 포인트로 mapping하며 skip list는 거꾸로 포인트를 사용자로 mapping시켜준다.  
  Sorted set에서 사용자들은 포인트로 정렬된다.

- Sorted set을 더 쉽게 이해하기 위해 이 데이터 타입을 아래 그림과 같이 score, member column들로 구성된 table로 생각해보자.  
  테이블은 score를 기준으로 내림차순으로 정렬되어 있다.

  ![picture 83](/images/SDI2_RGL_8.png)

- 이번 장에서 sorted set의 전체 구현에 대해 깊이 들어가진 않을 것이지만, 개략적인 아이디어만 살펴보자.

- Skip list는 빠른 검색을 지원하는 list이다. Skip list는 base sorted linked list와 multi-level index들로 구성된다.  
  예시를 보자. 아래 그림에서 base list는 정렬된 singly-linked list이다. 따라서 삽입, 삭제, 그리고 검색의 시간 복잡도는  
  $O(n)$ 이다.

  ![picture 84](/images/SDI2_RGL_9.png)

- 이 연산들을 어떻게 더 빠르게 만들 수 있을까? 한 가지 아이디어로 binary search 알고리즘과 마찬가지로 데이터들의 가운데로 빠르게  
  접근할 수 있다. 이를 위해 node를 1개씩 건너뛰는 level 1 index를 추가하고, level 1 index가 지나가는 node들을 건너뛰는  
  level 2 index를 만들어보자. 계속해서 추가적인 level을 만들고, 각 level은 이전 level이 지나가는 node들을 건너뛰도록 한다.  
  이 level은 node들 간의 거리가 $2/n - 1$이 될 때까지 계속한다.(_n_ : node 개수)  
  위 그림에 나타난 것처럼 45라는 숫자를 찾는 과정은 multi-level indexes를 사용하면 훨씬 빠르다.

- 데이터가 적으면 skip list를 사용해 시간을 줄이는 것이 그렇게 큰 효과를 나타내지 않는다. 아래 그림은 5 level의 index들로 구성된  
  skip list를 나타낸다. Base linked list에서는 원하는 데이터를 찾기 위해 62번 순회해야 한다. 하지만 skip list를 사용하면  
  오직 11개의 node들만을 순회하면 된다.

  ![picture 85](/images/SDI2_RGL_10.png)

- Sorted set은 각 element가 자동으로 삽입, 갱신 시 자동으로 정렬되기에 RDBMS보다 훨씬 더 효율적이다.  
  실제로 sorted set의 추가, 갱신 연산의 시간 복잡도는 $O(log(n))$이다.

- 한편 RDBMS에서 특정 사용자의 순위를 알아내려면 nested query를 수행해야 한다.

  ```sql
  SELECT *, (SELECT COUNT(*) FROM leaderboard lb2
  WHERE lb2.score >= lb1.score) RANK
  FROM leaderboard lb1
  WHERE lb1.user_id = {:user_id};
  ```

#### Redis를 사용한 구현

- 이제 Redis sorted set이 빠르다는 것을 알게 되었으니, 순위표를 구현하는 데에 필요한 Redis 연산들을 살펴보자.

  - `ZADD`: Set에 사용자를 추가한다. 만약 이미 해당 사용자 정보가 있다면, 갱신한다. 시간 복잡도는 $O(log(n))$이다.
  - `ZINCRBY`: 주어진 수치만큼 특정 사용자의 점수를 증가시킨다. 만약 사용자가 set에 없다면 점수를 0에서 시작되도록 한다.  
    시간 복잡도는 $O(log(n))$이다.
  - `ZRANGE/ZREVERANGE`: 점수로 정렬된 특정 범위의 사용자들을 조회한다. 정렬 기준과 조회할 결과 개수, 그리고 시작 position을  
    지정할 수 있다. 일반적으로 $O(log(n)+m)$의 시간복잡도를 가지는데, _m_ 은 조회할 결과의 개수를 의미하며 _n_ 은 sorted set에  
    저장된 entry의 개수이다.
  - `ZRANK/ZREVERANK`: 점수를 오름차순 또는 내림차순특정 정렬했을 때 사용자의 위치를 조회한다. 시간 복잡도는 $O(log(n))$이다.

#### Sorted set을 활용한 worfklow

- (1) 사용자가 포인트를 획득하는 경우

  ![picture 86](/images/SDI2_RGL_11.png)

  - 매달 생성되는 새로운 순위표를 위한 sorted set도 마찬가지로 매달 생성되며, 이전 데이터들은 historical data storage로 이동된다.  
    사용자가 경기에서 승리해 1점을 획득했다고 했을 때, 해당 달의 순위표 데이터를 담는 sorted set에 대해 `ZINCRBY`를 사용해 해당  
    사용자의 점수를 1 증가시킬 수 있다. 이 명령어는 해당 사용자 정보가 sorted set에 없다면 자동으로 추가시킨다.

    ```sh
    ZINCRBY leaderboard_aug_2022 1 'mary123'
    ```

- (2) 사용자가 순위표에서 top 10을 조회하는 경우

  ![picture 87](/images/SDI2_RGL_12.png)

  - 이 경우에는 점수를 기준으로 내림차순으로 정렬된 사용자들을 가져오기 위해 `ZREVRANGE`를 사용해야 한다. 그리고 WITHSCORES  
    속성을 지정해 사용자 정보와 함께 포인트 정보도 가져오도록 한다.

    ```sh
    ZREVERANGE leaderboard_aug_2022 0 9 WITHSCORES
    ```

  - 위 명령어는 아래와 같은 결과를 반환한다.

    ```
    [(user2,score2),(user1,score1),(user5,score5),...]
    ```

- (3) 사용자가 순위표에서 자신의 순위를 조회하는 경우

  ![picture 88](/images/SDI2_RGL_13.png)

- (4) 아래 그림과 같이 특정 사용자의 상대적인 순위 정보를 조회하는 경우

  ![picture 89](/images/SDI2_RGL_14.png)

  - 이 case는 명시적 요구사항은 아니지만, `ZREVERANGE` 연산을 사용하면 특정 순위 범위 내의 데이터를 가져올 수 있다.  
    예를 들어, 위 그림처럼 Mallow007의 순위가 361이라 하고 위 아래 4명의 사용자 정보를 더 조회하고 싶다면 아래처럼 명령을 수행하면 된다.

    ```sh
    ZREVERANGE leaderboard_aug_2022 357 365
    ```

### Storage 요구사항

- 이 시스템은 최소한 사용자의 id와 점수는 저장해야 한다. 그리고 최악의 시나리오, 즉 데이터가 가장 많이 저장되는 시나리오는 2500만명의  
  사용자(MAU)들이 모두 최소 1개의 게임에서 승리해 2500만개의 entry가 저장되는 경우이다. 사용자 id가 24-character string이고  
  점수가 16-bit integer(2bytes)라고 했을 때 한 사용자는 26byte의 공간을 차지하게 된다. 방금 본 최악의 시나리오를 생각해보면  
  `26bytes * 2500만 = 650MB`의 저장 공간이 매달 필요하다. 이 정도의 크기는 한 대의 현대 Redis server가 충분히 감당 가능하다.

- 연관된 다른 요소로 CPU와 I/O usage가 있다. 개략적 추정치를 계산할 때 peak QPS가 초당 2500건의 갱신 작업이었다.  
  이 QPS 또한 한 대의 현대 Redis server로 충분히 처리할 수 있다.

- Redis cache에 대한 한 가지 우려되는 부분은 영속성(persistence)이다. 이는 Redis node가 장애가 날 수 있기 때문이다.  
  운 좋게도 Redis는 영속성을 지원하지만 큰 Redis instance를 디스크로부터 재시작하는 것은 시간이 오래 걸린다.  
  따라서 일반적으로 Redis는 read replica도 함께 구성해 main instance가 장애가 나면 read replica를 main으로 promote하고  
  새로운 read replica를 생성하는 식으로 구성된다.

- 또한 MySQL과 같은 RDBMS에 2개의 supporting table(`user`, `point`)을 가져가야 한다. `user` table은 사용자 ID,  
  사용자 닉네임 등 운영에 필요한 사용자의 모든 데이터를 가질 것이다. 그리고 `point` 테이블은 사용자 id, 점수, 그리고 게임에서  
  승리한 시각 등의 추가적인 정보들을 가질 것이다. 이 두 테이블들을 활용해 게임 내역 등 다른 기능들을 개발할 수 있으며  
  인프라 장애 발생 시 Redis에 저장된 순위 정보를 다시 생성할 수도 있다.

---

## 상세 설계

- 개략적 설계를 다뤄보았으니 아래의 내용들을 자세히 다뤄보자.

  - Cloud provider를 사용할지의 여부

    - 서비스 직접 관리
    - AWS와 같은 cloud provider 사용

  - Redis의 확장
  - 대안: NoSQL
  - 그 외의 고려 사항들

### Cloud provider를 사용할지의 여부

- 존재하는 인프라에 따라 시스템을 배포하는 데에는 일반적으로 두 가지 선택지가 존재한다.

#### 서비스 직접 관리

- 이대로 하면 매달마다의 순위표 데이터를 저장하기 위해 leaderboard sorted set을 매달 만들어야 한다. Sorted set은 사용자와 점수를  
  저장한다. 프로필, 사용자명 등 이외의 사용자 데이터는 MySQL 데이터베이스에 저장된다. 순위표를 조회할 때 API server는 leaderboard  
  sorted set의 데이터 외에 각 사용자의 이름과 프로필 이미지 등을 데이터베이스에서 가져와야 한다. 장기적으로 봤을 때 이 프로세스가 너무  
  비효율적인 것 같다면 top 10 사용자들의 정보를 모두 caching해둘 수 있다. 이 설계는 아래 그림과 같다.

  ![picture 90](/images/SDI2_RGL_15.png)

#### AWS와 같은 cloud provider 사용

- 이 접근법은 클라우드 인프라를 적극 도입한다. 우리가 AWS를 사용하기로 했다고 생각해보자. 그렇다면 Amazon API Gateway, AWS Lambda를  
  사용해볼 수 있을 것이다. Amazon API Gateway는 RESTful API를 위한 HTTP endpoint를 생성해 backend service들로 전달해준다.  
  그리고 AWS lambda가 backend service로 동작하게 된다. RESTful API와 lambda function의 mapping 관계는 아래와 같다.

  | APIs                       | Lambda function            |
  | -------------------------- | -------------------------- |
  | `GET /v1/scores`           | LeaderboardFetchTop10      |
  | `GET /v1/scores/{user_id}` | LeaderboardFetchPlayerRank |
  | `POST /v1/scores`          | LeaderboardUpdateScore     |

- 개략적으로 봤을 때 게임은 Amazon API Gateway를 호출하고, 호출된 API gateway는 Lambda function을 호출해 요청을 처리한다.  
  따라서 AWS Lambda function이 Redis, MySQL와 같은 storage layer와 상호작용하게 된다.

- 사용자가 점수를 획득했을 경우, 아래와 같이 처리된다.

  ![picture 91](/images/SDI2_RGL_16.png)

- 순위표를 조회하는 경우는 아래와 같다.

  ![picture 92](/images/SDI2_RGL_17.png)

- Lambda는 serverless이기 때문에 Lambda function이 부하를 받으면 auto scaling이 알아서 처리된다. 따라서 우리는 확장과  
  환경 설정, 그리고 운영을 할 필요가 없다.

### Redis의 확장

- 500만명의 DAU와 storage, QPS 요구사항을 만족시키기 위해서는 한 대의 Redis server로 충분히 감당 가능하다. 하지만 만약 DAU가  
  100배 증가해 5억명이 되었다면 어떻게 될까? 이 경우 순위표 데이터의 최악 시나리오는 `650MB * 100 = 65GB`가 되며 QPS는  
  `2500 * 100 = 250000`이 된다. 따라서 sharding을 적용해야 할 필요가 있다.

#### Data sharding

- Data sharding을 하기 위해 fixed partition, hash partition을 고려해볼 수 있다.

##### Fixed partition

- Fixed partition을 이해하기 위해 순위표에 존재할 수 있는 점수의 범위를 먼저 생각해보자. 점수가 1~1000의 범위를 가지고, 데이터를  
  범위별로 쪼개보자. 예를 들어 10개의 shard가 존재한다면 `1~100`, `101~200`과 같이 각 shard가 가질 수 있는 점수 데이터의 범위를  
  지정하는 것이다.

  ![picture 93](/images/SDI2_RGL_18.png)

- 위와 같이 sharding하려면 순위표 데이터가 점수의 범위별로 고르게 분포되어 있어야 한다. 그렇지 않다면 sharding될 점수의 범위를 각  
  shard마다 조정해 상대적으로 균등하게 데이터가 sharding되도록 해야 한다. 따라서 애플리케이션 코드에서 직접 sharding 로직을 관리하게 된다.

- 특정 사용자의 점수를 갱신하거나 새롭게 입력하려면 해당 사용자 데이터가 어떤 shard에 있는지 알아야 한다. 이는 MySQL에 저장된 데이터를  
  토대로 해당 사용자의 점수를 계산해내어 shard를 찾아내는 방법으로 가능하다. 동작은 하지만 user ID를 점수로 mapping하는 데이터를  
  secondary cache에 저장해 성능을 더 좋게 할 수 있다. 또한 사용자의 점수에 변동이 생겨 다른 shard로 이동해야 하는 경우를 주의해야 한다.  
  이 경우에서는 이전 정보를 지우고, 다른 shard에 데이터를 다시 저장해야 한다.

- 순위표의 top 10 사용자를 조회하려면 가장 큰 점수 범위를 가지는 shard에서 10명의 정보를 가져오면 된다. 위 예시 그림대로 sharding이  
  되어 있다면 `[901,1000]`의 점수 범위를 갖는 shard에서 top 10 사용자들을 가져올 수 있을 것이다.

- 특정 사용자의 순위를 알아내려면 해당 사용자 데이터를 가지는 shard 내에서의 순위(local rank)와 함께 자신보다 높은 점수 범위를 갖는  
  shard들이 가지는 사용자 수를 모두 알아야 한다.

  > Shard 내의 모든 사용자 수를 구하려면 `info keyspace` 명령을 사용하면 되며, 이는 $O(1)$의 시간 복잡도를 가진다.

##### Hash partition

- Hash partition은 Redis cluster를 사용하며 점수들이 균등하게 분포되어 있지 않은 경우에 적합하다. Redis cluster는 여러 개의  
  Redis node들에 데이터를 자동으로 sharding하기 위한 방법을 제공하는데, 이 방법은 consistent hashing을 사용하지 않으며 그 대신  
  모든 key를 **hash slot**의 부분으로 처리하는 방식으로 구현된다.

- 총 16384개의 hash slot들이 있을 때 특정 key를 가지는 entry가 저장될 hash slot을 `CRC16(key) % 16384`의 계산을 통해  
  알아낼 수 있다. 이 방식을 사용하면 모든 key를 재분배하지 않고도 cluster 내에 node를 추가하거나 삭제할 수 있다.

  ![picture 94](/images/SDI2_RGL_19.png)

- 위 그림에는 총 3개의 node들이 있다.

  - node 1: `[0, 5500]`의 hash slot
  - node 2: `[5501, 11000]`의 hash slot
  - node 3: `[11001, 16383]`의 hash slot

- 점수를 갱신하려면 단순히 `CRC16(key) % 16384`를 계산해 해당 사용자 데이터가 저장된 shard를 알아내고 수행하면 된다.  
  반면 순위표의 top 10 사용자를 조회하는 작업은 이에 비해 복잡하다. 우선 모든 shard 각각에서 top 10 사용자 정보를 가져온 후  
  애플리케이션 코드에서 정렬해 최종 top 10 사용자를 추려내야 한다. 아래 그림은 이 작업의 예시이다.

  ![picture 95](/images/SDI2_RGL_20.png)

- 이 방식은 아래와 같은 한계점들을 가진다.

  - _k_ 가 굉장히 큰 숫자라 가정했을 때 top _k_ 개의 순위 데이터를 조회하려면 각 shard에서 가져와야 하는 데이터량도 많아지고  
    정렬되어야 하는 데이터도 많아지므로 latency가 증가한다.

  - 가장 느린 shard의 데이터 조회 결과까지 기다려야 하므로 partition 개수가 많으면 많을 수록 latency가 증가한다.

  - 특정 사용자의 순위를 조회하는 기능을 구현하기 위한 뾰족한 방법을 제공하지 않는다.

#### Redis node 크기 결정

- Redis node의 크기를 결정할 때에는 많은 사항들을 고려해야 한다. Write-heavy 애플리케이션은 모든 write 연산을 처리하고 장애 시  
  사용하기 위한 snapshot을 만들어야 하기 때문에 훨씬 더 많은 메모리를 필요로 한다. 안전을 위해 write-heavy 애플리케이션의 경우에는  
  추정되는 메모리 사용량의 2배를 할당해주도록 하자.

- Redis는 Redis의 성능을 benchmark할 수 있는 Redis-benchmark라는 툴을 제공한다. 이 툴은 여러 개의 query를 수행하도록 하는  
  여러 클라이언트를 흉내내 초당 처리할 수 있는 request의 수를 알아낼 수 있도록 한다.

### 대안: NoSQL

- Redis의 대안으로 NoSQL 데이터베이스를 고려해볼 수 있다. 어떤 종류의 NoSQL 데이터베이스를 사용해야할까?  
  이상적으로 아래의 특징을 가지면 좋을 것이다.

  - Write 연산의 최적화
  - 특정 partition내의 item들을 점수를 기준으로 효율적으로 정렬

- Amazon DynamoDB, Cassandra, MongoDB 등의 NoSQL 데이터베이스들이 좋아보인다. 이번 장에서는 Amazon DynamoDB를 사용해보자.

  ![picture 96](/images/SDI2_RGL_21.png)

- 체스 게임을 위한 순위표를 만들어 본다고 생각해보자. 아래 그림은 순위표와 사용자 table의 비정규화된 모습으로, 순위표를 나타내기 위한 모든  
  데이터를 포함하고 있다.

  ![picture 97](/images/SDI2_RGL_22.png)

- 위 table 스키마는 동작하지만 확장성이 부족하다. 더 많은 row들이 추가될 수록 상위 점수를 가진 사용자들을 가져오기 위해 전체 table을  
  scan해야 하기 때문이다.

- Linear scan을 회피하기 위해서는 index를 추가해야 한다. 첫 번째로 아래 그림처럼 `game_name#{year_month}`를 partition key로,  
  점수를 sort key로 갖는 global secondary index를 추가해보자.

  ![picture 98](/images/SDI2_RGL_23.png)

- 이 방식도 동작은 하지만 부하가 많으면 문제가 발생할 수 있다. DynamoDB는 consistent hashing을 적용해 데이터를 여러 개의 node들로  
  분산시킨다. 각 item은 자신의 key에 의해 계산된 node에 저장된다. 따라서 데이터가 여러 partition들에 균등하게 분배되도록 데이터를  
  설계해야 한다. 위 그림처럼 설계하면 가장 최근 달의 모든 데이터는 하나의 partition에 저장될 것이고, 이는 hot partition 문제를  
  야기할 것이다. 그렇다면 이를 어떻게 해결할 수 있을까?

- 먼저 partition number(`user_id % number_of_partitions`)를 partition key에 append해 데이터를 _n_ 개의 partition에  
  분배시킬 수 있다. 이 패턴을 write sharding이라 한다. Write sharding은 read, write 연산 모두에 복잡도를 더하기 때문에  
  tradeoff를 세밀히 고려해야 한다.

- 그렇다면 partition은 몇 개를 가져야 할까? Partition 개수는 write volume 또는 DAU에 의해 결정할 수 있을 것이다.  
  기억해야 할 중요한 것은 partition이 많아질 수록 read 연산의 복잡도가 증가한다는 것이다. 같은 달의 모든 데이터가 여러 개의  
  partition들에 균등하게 분배되므로 하나의 partition이 처리해야 할 부하가 굉장히 줄어든다. 하지만 주어진 달의 데이터를 모두 읽으려면  
  모든 partition의 데이터를 가져와 병합해야 하기 때문에 복잡도가 증가한다.

- 개선된 partition key는 `game_name#{year_month}#p{partition_number}`의 형식을 가진다. 아래 그림을 보자.

  ![picture 99](/images/SDI2_RGL_24.png)

- 이제 GSI는 `game_name#{year_month}#p{partition_number}`를 partition key로, 점수를 sort key로 사용한다.  
  따라서 전체 데이터가 아닌 특정 partition 내의 데이터만 정렬(locally sort)할 수 있는 상황이 된다. 3개의 partition들이 있다면  
  top 10 순위표 데이터를 가져오기 위해 _"scatter-gather"_ 접근법을 사용해야 한다. 즉 이전에 본 것과 같이 각 partition에서  
  top 10개의 데이터를 가져오고, 애플리케이션 코드에서 이들을 정렬해 다시 top 10 개의 결과를 가져오도록 해야한다는 것이다.

  ![picture 100](/images/SDI2_RGL_25.png)

- Partition의 개수를 결정하려면 benchmarking을 자세히 해봐야 한다. 대부분의 경우 partition이 많으면 많을수록 각 partition이  
  처리할 부하가 줄어들지만 모든 partition의 데이터를 가져와 병합해야 하므로 복잡도가 증가한다.

- 하지만 Redis partition을 사용하는 방법과 비슷하게 이렇게 NoSQL을 사용하는 방법도 특정 사용자의 순위를 조회하는 기능을 구현하기 위한  
  뾰족한 수를 제공하지 않는다. 하지만 특정 사용자가 top 10\~20%에 속한다는 정보과 같이 해당 사용자가 속한 순위의 퍼센트를 가져오는  
  것은 가능하다. 실제로 애플리케이션에서도 12,000,001과 같은 정확한 순위보다는 top 10\~20%라는 정보가 사용자에게 더욱 유용할 것이다.  
  따라서 만약 데이터 규모가 sharding을 수행할만큼 크다면 점수들의 분포가 모든 shard들에 걸쳐 균등하게 분배되어 있다고 가정할 수 있다.  
  만약 이 가정이 사실이라면 각 shard의 점수를 분석해 결과를 caching하는 cron job을 만들어 사용할 수 있을 것이다.  
  이 cron job의 결과는 아래와 같을 것이다.

  ```
  10% => score < 100
  20% => score < 500
  ...
  90% => score < 6500
  ```

- 이렇게 되면 해당 사용자가 상위 20%에 속한다는 등의 정보를 쉽게 가져올 수 있을 것이다.

---

## 마무리

- 이번 장에서는 수백만의 DAU를 만족시키는 실시간 game leaderboard를 설계해보았다. 우선 가장 직관적이고 간단히 구현 가능한  
  MySQL 등의 RDBMS를 사용하는 방식을 보았고, 시스템의 규모를 제대로 처리하지 못하기 때문에 다른 대안들을 살펴보았다.  
  그 대안들로 Redis sorted set이 등장했다. 또한 Redis의 sharding을 통해 DAU가 100배 증가해 5억명이 되는 경우를 대비해보기도 했다.  
  마지막으로 NoSQL을 사용해 시스템의 요구사항을 충족시킬 수 있는 방법들도 다뤄보았다.

- 아래의 사항들도 고려해볼만 하다.

  - Redis Hash는 string 필드와 값 사이의 map을 제공한다. 이 Redis Hash를 아래의 2개 use case에 대해 적용해볼 수 있다.

    - (1) User ID와 해당 사용자의 부가적인 정보를 담는 객체와의 map을 저장한다. 이렇게 하면 데이터베이스에서 사용자의 부가 정보를  
      조회해오는 것보다 훨씬 더 빠른 조회 속도를 가져갈 수 있다.

    - (2) 2명의 사용자가 동일한 점수를 가지는 경우, 해당 점수에 먼저 도달한 사용자가 더 높은 순위로 처리되도록 할 수 있다.  
      사용자의 점수를 증가시킬 때, user ID와 가장 최근에 게임에 승리한 timestamp를 mapping시키는 것이다.  
      이렇게 했을 때 동일한 점수를 갖더라도 더 빠른 timestamp를 가지는 사용자가 더 높은 순위를 갖도록 처리할 수 있다.

  - 시스템 장애 복구

    - Redis cluster는 잠재적으로 규모가 큰 장애가 발생할 수 있다. 우리의 설계에서 사용자가 게임에서 승리할 때마다 승리한 시각, 획득한  
      포인트 등의 정보를 MySQL 데이터베이스에 저장시키는 script를 추가한다고 해보자. 이렇게 하면 Redis cluster가 장애가 나서  
      사용이 불가능한 상태가 되더라도 MySQL 데이터베이스의 record를 순회하면서 순위표를 위한 데이터를 만들어낼 수 있을 것이다.

---
